{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DropoutVAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl5YDWvEeu4a",
        "colab_type": "text"
      },
      "source": [
        "The purpose is to use Dropout in VAE in order to generate data.\n",
        "\n",
        "Origin VAE uses latent values to generate the data.\n",
        "However, with Dropout VAE, we use the mean of the latents to generate the data.\n",
        "\n",
        "\n",
        "The dataset used in notebook: [Customer Support](https://www.ibm.com/communities/analytics/watson-analytics-blog/guide-to-sample-datasets/)\n",
        "\n",
        "More example about VAE: [Modeling Telecom customer churn](https://towardsdatascience.com/modeling-telecom-customer-churn-with-variational-autoencoder-4e5cf6194871)\n",
        "\n",
        "Origin code for VAE in keras: [Building Autoencoders in keras](https://blog.keras.io/building-autoencoders-in-keras.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdT9BTrmT3ro",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNUpL6YT32X",
        "colab_type": "code",
        "outputId": "eaa36e85-ecc3-4860-8638-45e7b9457d0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import set_random_seed\n",
        "\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.layers import Lambda, Input, Dense, Dropout\n",
        "\n",
        "set_random_seed(1)\n",
        "np.random.seed(1)\n",
        "random.seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNKVLBOBgR3W",
        "colab_type": "text"
      },
      "source": [
        "# Path to dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4QUbkrWUl2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Access to resources\n",
        "path = '/Dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8zWTy_ePGg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intermediate_dim = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VTGWwfObeoT",
        "colab_type": "text"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfcE15dwhyaL",
        "colab_type": "code",
        "outputId": "1cd188b0-a4be-4a28-dbec-1e0f1d83bd5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import pandas as pd\n",
        "na_values = {'?', ' '}\n",
        "df = pd.read_csv(path,\n",
        "                 sep=',',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "                 \n",
        "df.fillna(method='ffill', inplace=True)\n",
        "df.dropna(axis=1, how='any', inplace=True)\n",
        "df.drop(['customerID'], axis=1, inplace=True)\n",
        "df = df.reset_index(drop=True)\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 20 columns):\n",
            "gender              7043 non-null object\n",
            "SeniorCitizen       7043 non-null int64\n",
            "Partner             7043 non-null object\n",
            "Dependents          7043 non-null object\n",
            "tenure              7043 non-null int64\n",
            "PhoneService        7043 non-null object\n",
            "MultipleLines       7043 non-null object\n",
            "InternetService     7043 non-null object\n",
            "OnlineSecurity      7043 non-null object\n",
            "OnlineBackup        7043 non-null object\n",
            "DeviceProtection    7043 non-null object\n",
            "TechSupport         7043 non-null object\n",
            "StreamingTV         7043 non-null object\n",
            "StreamingMovies     7043 non-null object\n",
            "Contract            7043 non-null object\n",
            "PaperlessBilling    7043 non-null object\n",
            "PaymentMethod       7043 non-null object\n",
            "MonthlyCharges      7043 non-null float64\n",
            "TotalCharges        7043 non-null float64\n",
            "Churn               7043 non-null object\n",
            "dtypes: float64(2), int64(2), object(16)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "   gender  SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n",
            "0  Female              0     Yes  ...          29.85         29.85    No\n",
            "1    Male              0      No  ...          56.95       1889.50    No\n",
            "2    Male              0      No  ...          53.85        108.15   Yes\n",
            "3    Male              0      No  ...          42.30       1840.75    No\n",
            "4  Female              0      No  ...          70.70        151.65   Yes\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptmiXDEjbhmp",
        "colab_type": "text"
      },
      "source": [
        "## Recognizing Categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfL6yO7HZR7E",
        "colab_type": "code",
        "outputId": "cbe8ac86-4153-430e-c0b2-4a77b311cf37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "colnums = len(df.columns)\n",
        "for i in df.columns:\n",
        "    try:\n",
        "        if df[i].dtype.name == 'object':\n",
        "            df[i] = df[i].astype('category')\n",
        "        else:\n",
        "            df[i].astype('float32')\n",
        "    except:\n",
        "        continue\n",
        "print(df.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   gender  SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n",
            "0  Female              0     Yes  ...          29.85         29.85    No\n",
            "1    Male              0      No  ...          56.95       1889.50    No\n",
            "2    Male              0      No  ...          53.85        108.15   Yes\n",
            "3    Male              0      No  ...          42.30       1840.75    No\n",
            "4  Female              0      No  ...          70.70        151.65   Yes\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpGxC2v2CDi1",
        "colab_type": "code",
        "outputId": "c3cedf9c-b6cc-49ac-c514-bf05ea17e239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "np.random.seed(1)\n",
        "\n",
        "vals = df.values.copy()\n",
        "total_nums = len(vals)\n",
        "\n",
        "train, validation = train_test_split(df, test_size=0.5, \n",
        "                                     random_state=42, \n",
        "                                     shuffle=True)\n",
        "\n",
        "validation = validation.reindex(sorted(validation.columns), axis=1)\n",
        "validation.to_csv(path + '_For_Test.csv')\n",
        "print(validation.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Churn        Contract Dependents  ... TotalCharges  gender  tenure\n",
            "185    Yes  Month-to-month         No  ...        24.80  Female       1\n",
            "2715    No  Month-to-month         No  ...       996.45    Male      41\n",
            "3825    No        Two year        Yes  ...      1031.70  Female      52\n",
            "1807   Yes  Month-to-month         No  ...        76.35  Female       1\n",
            "132     No        Two year         No  ...      3260.10    Male      67\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-52cnSrZHGm",
        "colab_type": "code",
        "outputId": "04d75d85-891b-40ae-876a-3b2bd90bac3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df = train\n",
        "categorical = df.select_dtypes(['category']).columns\n",
        "print(categorical)\n",
        "for f in categorical:\n",
        "    dummies = pd.get_dummies(df[f], prefix = f, prefix_sep = '_')\n",
        "    df = pd.concat([df, dummies], axis = 1)\n",
        "    \n",
        "# drop original categorical features\n",
        "df.drop(categorical, axis = 1, inplace = True)\n",
        "df.to_csv(path + '_For_Training.csv', index=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
            "       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
            "       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
            "       'PaperlessBilling', 'PaymentMethod', 'Churn'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnJXo9LfUGaJ",
        "colab_type": "text"
      },
      "source": [
        "# Define VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmIPmd5wjAM7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "df = pd.read_csv(path + '_For_Training.csv')\n",
        "train = df.values.copy()\n",
        "train.astype('float32')\n",
        "scaler = MinMaxScaler()\n",
        "train = scaler.fit_transform(train)\n",
        "x_train, x_test = train_test_split(train, test_size=0.5,\n",
        "                                  random_state=42,\n",
        "                                  shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNf-3EMl2usm",
        "colab_type": "code",
        "outputId": "c0cf40ca-564b-4ae4-c952-6495d77c066d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "original_dim = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, original_dim])\n",
        "x_test = np.reshape(x_test, [-1, original_dim])\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1760, 47)\n",
            "(1761, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy-JqW7Jpuyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "set_random_seed(1)\n",
        "\n",
        "class VAE:\n",
        "    def __init__(self, input_shape=(original_dim,), \n",
        "                 intermediate_dim=128, latent_dim=2, summary=False):\n",
        "        \n",
        "        self._build_model(input_shape,\n",
        "                         intermediate_dim, \n",
        "                          latent_dim, summary)\n",
        "    \n",
        "    def _build_model(self, input_shape, intermediate_dim, latent_dim,\n",
        "                    summary=False):\n",
        "        inputs = Input(shape=input_shape, name='encoder_input')\n",
        "        x = inputs\n",
        "        x = Dense(intermediate_dim, activation='relu')(x)\n",
        "        x = Dense(intermediate_dim//2, activation='relu')(x)\n",
        "        \n",
        "        z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "        z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "        z = Lambda(self.sampling, output_shape=(latent_dim,), \n",
        "                   name='z')([z_mean, z_log_var])\n",
        "\n",
        "        self.encoder = Model(inputs, [z_mean, z_log_var, z], \n",
        "                        name='encoder')\n",
        "        \n",
        "        latent_inputs = Input(shape=(latent_dim,), \n",
        "                              name='z_sampling')\n",
        "        x = latent_inputs\n",
        "        x = Dense(intermediate_dim//2, activation='relu')(x)\n",
        "        x = Dense(intermediate_dim, activation='relu')(x)\n",
        "        outputs = Dense(original_dim, activation='sigmoid')(x)\n",
        "\n",
        "        self.decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "        outputs = self.decoder(self.encoder(inputs)[2])\n",
        "        self.vae = Model(inputs, outputs, name='vae_mlp')\n",
        "        \n",
        "        reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
        "        reconstruction_loss *= original_dim\n",
        "        kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "        kl_loss = K.sum(kl_loss, axis=-1)\n",
        "        kl_loss *= -0.5\n",
        "        \n",
        "        vae_loss = K.mean(reconstruction_loss + kl_loss)\t\n",
        "        \n",
        "        self.vae.add_loss(vae_loss)\n",
        "        self.vae.compile(optimizer='adam')\n",
        "        if summary: \n",
        "            print(self.vae.summary())\n",
        "        \n",
        "    def sampling(self, args):\n",
        "        z_mean, z_log_var = args\n",
        "        batch = K.shape(z_mean)[0]\n",
        "        dim = K.int_shape(z_mean)[1]\n",
        "        epsilon = K.random_normal(shape=(batch, dim))\n",
        "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "        \n",
        "    def fit(self, x_train, x_test, epochs=100, batch_size=100,\n",
        "           verbose=1):\n",
        "        self.vae.fit(x_train, \n",
        "            shuffle=True,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            verbose=verbose,\n",
        "            validation_data=(x_test, None))\n",
        "    \n",
        "    def encoder_predict(self, x_test, batch_size=100):\n",
        "        return self.encoder.predict(x_test,\n",
        "                                   batch_size=batch_size)\n",
        "    \n",
        "    def generate(self, latent_val, batch_size=100):\n",
        "        return self.decoder.predict(latent_val)\n",
        "    \n",
        "    def predict(self, x_test, batch_size=100):\n",
        "        prediction = self.vae.predict(x_test, \n",
        "                                      batch_size=batch_size)\n",
        "        return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXhRjx02UYZN",
        "colab_type": "text"
      },
      "source": [
        "## Training VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd02caRJWGG8",
        "colab_type": "text"
      },
      "source": [
        "Just let the last value to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBbIF17p8iY2",
        "colab_type": "code",
        "outputId": "8a6e63b1-56df-4705-aa61-5117b94e4516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4406
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "set_random_seed(1)\n",
        "\n",
        "latent_dim = original_dim//2\n",
        "if latent_dim < 2:\n",
        "    latent_dim = 2\n",
        "vae = VAE(intermediate_dim=intermediate_dim, latent_dim=latent_dim)\n",
        "vae.fit(x_train, x_test, epochs=120)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0616 09:39:19.641215 140490864273280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0616 09:39:19.647317 140490864273280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0616 09:39:19.649481 140490864273280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0616 09:39:19.711625 140490864273280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "W0616 09:39:19.799512 140490864273280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0616 09:39:19.805992 140490864273280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0616 09:39:19.827493 140490864273280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1760 samples, validate on 1761 samples\n",
            "Epoch 1/120\n",
            "1760/1760 [==============================] - 1s 832us/step - loss: 30.2938 - val_loss: 28.4514\n",
            "Epoch 2/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 28.5110 - val_loss: 28.0947\n",
            "Epoch 3/120\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 27.8977 - val_loss: 26.9848\n",
            "Epoch 4/120\n",
            "1760/1760 [==============================] - 0s 86us/step - loss: 25.7558 - val_loss: 24.2887\n",
            "Epoch 5/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 23.6874 - val_loss: 23.1689\n",
            "Epoch 6/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 22.7504 - val_loss: 22.6479\n",
            "Epoch 7/120\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 22.4309 - val_loss: 22.4008\n",
            "Epoch 8/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 21.9684 - val_loss: 21.9698\n",
            "Epoch 9/120\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 21.6370 - val_loss: 21.7277\n",
            "Epoch 10/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 21.3966 - val_loss: 21.5939\n",
            "Epoch 11/120\n",
            "1760/1760 [==============================] - 0s 88us/step - loss: 21.3361 - val_loss: 21.5198\n",
            "Epoch 12/120\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 21.1195 - val_loss: 21.4764\n",
            "Epoch 13/120\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 21.2189 - val_loss: 21.3759\n",
            "Epoch 14/120\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 20.9702 - val_loss: 21.1666\n",
            "Epoch 15/120\n",
            "1760/1760 [==============================] - 0s 88us/step - loss: 20.8441 - val_loss: 21.0260\n",
            "Epoch 16/120\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 20.8684 - val_loss: 20.9319\n",
            "Epoch 17/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 20.5597 - val_loss: 20.7560\n",
            "Epoch 18/120\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 20.5319 - val_loss: 20.6576\n",
            "Epoch 19/120\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 20.3791 - val_loss: 20.3633\n",
            "Epoch 20/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 20.0059 - val_loss: 20.0084\n",
            "Epoch 21/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 19.8869 - val_loss: 19.9456\n",
            "Epoch 22/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 19.6626 - val_loss: 19.8484\n",
            "Epoch 23/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 19.4510 - val_loss: 19.9323\n",
            "Epoch 24/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 19.3638 - val_loss: 19.6385\n",
            "Epoch 25/120\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 19.3264 - val_loss: 19.5607\n",
            "Epoch 26/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 19.2002 - val_loss: 19.4981\n",
            "Epoch 27/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 19.2078 - val_loss: 19.2859\n",
            "Epoch 28/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 19.0251 - val_loss: 19.2933\n",
            "Epoch 29/120\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 18.9037 - val_loss: 19.1532\n",
            "Epoch 30/120\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 18.8282 - val_loss: 19.1261\n",
            "Epoch 31/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 18.8579 - val_loss: 19.0476\n",
            "Epoch 32/120\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 18.7364 - val_loss: 18.9829\n",
            "Epoch 33/120\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 18.5737 - val_loss: 18.8826\n",
            "Epoch 34/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 18.6818 - val_loss: 18.9617\n",
            "Epoch 35/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 18.6071 - val_loss: 18.8622\n",
            "Epoch 36/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 18.4909 - val_loss: 18.8098\n",
            "Epoch 37/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 18.3748 - val_loss: 18.6221\n",
            "Epoch 38/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 18.4288 - val_loss: 18.8471\n",
            "Epoch 39/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 18.3035 - val_loss: 18.5118\n",
            "Epoch 40/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 18.3042 - val_loss: 18.5992\n",
            "Epoch 41/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 18.3253 - val_loss: 18.4665\n",
            "Epoch 42/120\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 18.2521 - val_loss: 18.3825\n",
            "Epoch 43/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 18.0387 - val_loss: 18.3575\n",
            "Epoch 44/120\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 17.8658 - val_loss: 18.3401\n",
            "Epoch 45/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 17.9163 - val_loss: 18.2158\n",
            "Epoch 46/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 17.7643 - val_loss: 18.3133\n",
            "Epoch 47/120\n",
            "1760/1760 [==============================] - 0s 88us/step - loss: 17.9248 - val_loss: 18.1688\n",
            "Epoch 48/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 17.7607 - val_loss: 18.2551\n",
            "Epoch 49/120\n",
            "1760/1760 [==============================] - 0s 88us/step - loss: 17.7697 - val_loss: 18.1779\n",
            "Epoch 50/120\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 17.8128 - val_loss: 18.0023\n",
            "Epoch 51/120\n",
            "1760/1760 [==============================] - 0s 87us/step - loss: 17.6538 - val_loss: 18.0445\n",
            "Epoch 52/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 17.7417 - val_loss: 17.9594\n",
            "Epoch 53/120\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 17.5340 - val_loss: 17.8384\n",
            "Epoch 54/120\n",
            "1760/1760 [==============================] - 0s 88us/step - loss: 17.5037 - val_loss: 17.9168\n",
            "Epoch 55/120\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 17.6436 - val_loss: 17.9171\n",
            "Epoch 56/120\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 17.5667 - val_loss: 17.8416\n",
            "Epoch 57/120\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.5472 - val_loss: 17.9408\n",
            "Epoch 58/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 17.2402 - val_loss: 17.7471\n",
            "Epoch 59/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 17.2870 - val_loss: 17.7527\n",
            "Epoch 60/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 17.3722 - val_loss: 17.8125\n",
            "Epoch 61/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 17.3167 - val_loss: 17.9441\n",
            "Epoch 62/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 17.3641 - val_loss: 17.6312\n",
            "Epoch 63/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 17.1481 - val_loss: 17.8308\n",
            "Epoch 64/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 17.1984 - val_loss: 17.6942\n",
            "Epoch 65/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 17.2613 - val_loss: 17.4481\n",
            "Epoch 66/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 16.9672 - val_loss: 17.4931\n",
            "Epoch 67/120\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 16.9597 - val_loss: 17.4519\n",
            "Epoch 68/120\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 17.0808 - val_loss: 17.5357\n",
            "Epoch 69/120\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 16.9708 - val_loss: 17.4404\n",
            "Epoch 70/120\n",
            "1760/1760 [==============================] - 0s 88us/step - loss: 16.9503 - val_loss: 17.2927\n",
            "Epoch 71/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.9455 - val_loss: 17.2062\n",
            "Epoch 72/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 16.8578 - val_loss: 17.3841\n",
            "Epoch 73/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.8068 - val_loss: 17.3451\n",
            "Epoch 74/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.7917 - val_loss: 17.2803\n",
            "Epoch 75/120\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 16.7276 - val_loss: 17.4009\n",
            "Epoch 76/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.7081 - val_loss: 17.2858\n",
            "Epoch 77/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 16.5992 - val_loss: 17.3058\n",
            "Epoch 78/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.7556 - val_loss: 17.3011\n",
            "Epoch 79/120\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 16.6941 - val_loss: 17.2265\n",
            "Epoch 80/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 16.6974 - val_loss: 17.1206\n",
            "Epoch 81/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 16.5747 - val_loss: 17.1813\n",
            "Epoch 82/120\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 16.5221 - val_loss: 17.1079\n",
            "Epoch 83/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 16.5560 - val_loss: 16.9868\n",
            "Epoch 84/120\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 16.3783 - val_loss: 16.9954\n",
            "Epoch 85/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 16.5983 - val_loss: 17.0585\n",
            "Epoch 86/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.5973 - val_loss: 17.1707\n",
            "Epoch 87/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 16.3841 - val_loss: 17.1726\n",
            "Epoch 88/120\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 16.4392 - val_loss: 17.0201\n",
            "Epoch 89/120\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 16.3708 - val_loss: 17.2047\n",
            "Epoch 90/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.3654 - val_loss: 16.9748\n",
            "Epoch 91/120\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 16.2435 - val_loss: 16.8586\n",
            "Epoch 92/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.3131 - val_loss: 16.7752\n",
            "Epoch 93/120\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 16.1850 - val_loss: 16.7539\n",
            "Epoch 94/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.0808 - val_loss: 16.8500\n",
            "Epoch 95/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 16.2034 - val_loss: 16.7725\n",
            "Epoch 96/120\n",
            "1760/1760 [==============================] - 0s 88us/step - loss: 16.1071 - val_loss: 16.7802\n",
            "Epoch 97/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.1913 - val_loss: 16.8087\n",
            "Epoch 98/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.1540 - val_loss: 16.9072\n",
            "Epoch 99/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 16.0197 - val_loss: 16.7885\n",
            "Epoch 100/120\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.8636 - val_loss: 16.8259\n",
            "Epoch 101/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.2616 - val_loss: 16.7112\n",
            "Epoch 102/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.0101 - val_loss: 16.5623\n",
            "Epoch 103/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 15.9148 - val_loss: 16.7171\n",
            "Epoch 104/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.9790 - val_loss: 16.7963\n",
            "Epoch 105/120\n",
            "1760/1760 [==============================] - 0s 112us/step - loss: 15.9371 - val_loss: 16.7057\n",
            "Epoch 106/120\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 15.8500 - val_loss: 16.6335\n",
            "Epoch 107/120\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.9993 - val_loss: 16.6034\n",
            "Epoch 108/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.7588 - val_loss: 16.5899\n",
            "Epoch 109/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 15.8053 - val_loss: 16.7673\n",
            "Epoch 110/120\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.8284 - val_loss: 16.6918\n",
            "Epoch 111/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 15.8707 - val_loss: 16.6408\n",
            "Epoch 112/120\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 15.7778 - val_loss: 16.6676\n",
            "Epoch 113/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 15.8157 - val_loss: 16.5819\n",
            "Epoch 114/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.7020 - val_loss: 16.7666\n",
            "Epoch 115/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 15.8548 - val_loss: 16.4355\n",
            "Epoch 116/120\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 15.7214 - val_loss: 16.4912\n",
            "Epoch 117/120\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.7618 - val_loss: 16.5812\n",
            "Epoch 118/120\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 15.8698 - val_loss: 16.4535\n",
            "Epoch 119/120\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 15.6562 - val_loss: 16.5970\n",
            "Epoch 120/120\n",
            "1760/1760 [==============================] - 0s 89us/step - loss: 15.6976 - val_loss: 16.3315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTfvSN_R2c76",
        "colab_type": "code",
        "outputId": "9efc5c86-43a0-4827-aa96-668950769406",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import time\n",
        "np.random.seed(1)\n",
        "\n",
        "start = time.time()\n",
        "x_test = np.reshape(x_test, (-1, original_dim))\n",
        "x_test_encoded = vae.encoder.predict(x_test)\n",
        "x_test_encoded = np.asarray(x_test_encoded)\n",
        "\n",
        "total_nums = 2\n",
        "results = []\n",
        "for i in range(x_test_encoded.shape[1]):\n",
        "    latent_gen = []\n",
        "    for _ in range(total_nums):\n",
        "        epsilon = np.random.normal(0., 1., x_test_encoded.shape[2])\n",
        "        latent_gen.extend([x_test_encoded[0, i, :] + np.exp(x_test_encoded[1, i, :]*0.5)*epsilon])\n",
        "    latent_gen = np.asarray(latent_gen)\n",
        "    results.append(vae.generate(latent_gen))\n",
        "    \n",
        "results = np.asarray(results)\n",
        "results = np.reshape(results, (-1, original_dim))\n",
        "print(results.shape)\n",
        "results = scaler.inverse_transform(results)\n",
        "end = time.time()\n",
        "print('Total time=', end-start)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3522, 47)\n",
            "Total time= 2.0170202255249023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6DiGV8MV9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {}\n",
        "names = list(df)\n",
        "for i, name in enumerate(names):\n",
        "    d[name] = results[:, i]\n",
        "df = pd.DataFrame(data=d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49_bbWWCsrHG",
        "colab_type": "code",
        "outputId": "1590e1aa-7d2c-4871-a4ab-f7a6f7fbd51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "names = list(df)\n",
        "c_dict = {}\n",
        "for n in names:\n",
        "    if '_' in n:\n",
        "        index = n.index('_')\n",
        "        c_dict[n[:index]] = [c for c in names if n[:index+1] in c]\n",
        "values = []\n",
        "for key, items in c_dict.items():\n",
        "    dummies = df[items]\n",
        "    d_names = list(dummies)\n",
        "    c_dict = {}\n",
        "    for n in d_names:\n",
        "        c_dict[n] = n[n.index('_')+1:]\n",
        "    dummies.rename(columns=c_dict, \n",
        "                   inplace=True)\n",
        "    df[key] = dummies.idxmax(axis=1)\n",
        "    df.drop(items, axis=1, inplace=True)\n",
        "print(df.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   SeniorCitizen     tenure  ...            PaymentMethod  Churn\n",
            "0       0.339908  37.876163  ...         Electronic check     No\n",
            "1       0.251621  34.850628  ...  Credit card (automatic)     No\n",
            "2       0.177261  62.554085  ...         Electronic check     No\n",
            "3       0.076042  64.294090  ...  Credit card (automatic)     No\n",
            "4       0.409789   5.142932  ...         Electronic check    Yes\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ljK-ceANBih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reindex(sorted(df.columns), axis=1)\n",
        "df.to_csv(path + '_vae.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SZr05ADu6LQP"
      },
      "source": [
        "# Dropout VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9KXhkZujT29r",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "df = pd.read_csv(path + '_For_Training.csv')\n",
        "train = df.values.copy()\n",
        "train.astype('float32')\n",
        "scaler = MinMaxScaler()\n",
        "train = scaler.fit_transform(train)\n",
        "x_train, x_test = train_test_split(train, test_size=0.5,\n",
        "                                  random_state=42,\n",
        "                                  shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "802d6f66-3565-421f-c044-65e29193a5cc",
        "id": "fa5UJs9cT29v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "original_dim = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, original_dim])\n",
        "x_test = np.reshape(x_test, [-1, original_dim])\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1760, 47)\n",
            "(1761, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MnKFnBX-6LQR",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l2\n",
        "from keras.losses import categorical_crossentropy\n",
        "np.random.seed(1)\n",
        "\n",
        "class DropoutVAE:\n",
        "    def __init__(self, input_shape=(original_dim,), \n",
        "                 intermediate_dim=32, latent_dim=3, dropout=0.05, \n",
        "                 summary=False):\n",
        "        \n",
        "        self._build_model(input_shape,\n",
        "                         intermediate_dim, \n",
        "                          latent_dim, summary,\n",
        "                          dropout)\n",
        "    \n",
        "    def _build_model(self, input_shape, intermediate_dim, latent_dim,\n",
        "                    summary=False, dropout=0.05):\n",
        "        inputs = Input(shape=input_shape, name='encoder_input')\n",
        "        x = inputs\n",
        "        x = Dense(intermediate_dim, activation='relu')(x)\n",
        "        x = Dense(intermediate_dim//2, activation='relu')(x)\n",
        "        \n",
        "        z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "        z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "        self.encoder = Model(inputs, [z_mean, z_log_var], name='encoder')\n",
        "        \n",
        "        latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "        x = latent_inputs\n",
        "        x = Dense(intermediate_dim//2, activation='relu',\n",
        "                 kernel_regularizer=l2(1e-4),\n",
        "                 bias_regularizer=l2(1e-4))(x)\n",
        "        x = Dropout(dropout)(x)\n",
        "        x = Dense(intermediate_dim, activation='relu',\n",
        "                 kernel_regularizer=l2(1e-4),\n",
        "                 bias_regularizer=l2(1e-4))(x)\n",
        "        x = Dropout(dropout)(x)\n",
        "        outputs = Dense(original_dim, activation='sigmoid',\n",
        "                       kernel_regularizer=l2(1e-4),\n",
        "                       bias_regularizer=l2(1e-4))(x)\n",
        "\n",
        "        self.decoder = Model(latent_inputs, \n",
        "                             outputs, \n",
        "                             name='decoder')\n",
        "        \n",
        "        outputs = self.decoder(self.encoder(inputs)[0])\n",
        "        self.vae = Model(inputs, outputs, \n",
        "                         name='vae_mlp')\n",
        "        \n",
        "        reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
        "        reconstruction_loss *= original_dim\n",
        "        kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "        kl_loss = K.sum(kl_loss, axis=-1)\n",
        "        kl_loss *= -0.5\n",
        "        \n",
        "        vae_loss = K.mean(reconstruction_loss + kl_loss)\t\n",
        "        \n",
        "        self.vae.add_loss(vae_loss)\n",
        "        self.vae.compile(optimizer='adam')\n",
        "        if summary: \n",
        "            print(self.vae.summary())\n",
        "        \n",
        "    def fit(self, x_train, x_test, epochs=100, batch_size=100,\n",
        "           verbose=1):\n",
        "        self.vae.fit(x_train, \n",
        "            shuffle=True,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            verbose=verbose,\n",
        "            validation_data=(x_test, None))\n",
        "    \n",
        "    def encoder_predict(self, x_test, batch_size=100):\n",
        "        return self.encoder.predict(x_test,\n",
        "                                   batch_size=batch_size)\n",
        "    \n",
        "    def generate(self, latent_val, batch_size=100):\n",
        "        return self.decoder.predict(latent_val)\n",
        "    \n",
        "    def predict(self, x_test, batch_size=1, nums=1000):\n",
        "        predict_stochastic = K.function([self.vae.layers[0].input,\n",
        "                                K.learning_phase()],\n",
        "                                [self.vae.get_output_at(0)])\n",
        "        Yt_hat = []\n",
        "        for _ in range(nums):\n",
        "            Yt_hat.append(predict_stochastic([x_test, 1])) \n",
        "            \n",
        "        return np.asarray(Yt_hat)\n",
        "    \n",
        "    def mean_predict(self, x_test, batch_size=1, nums=1000):\n",
        "        predict_stochastic = K.function([self.decoder.layers[0].input,\n",
        "                                K.learning_phase()],\n",
        "                                [self.decoder.get_output_at(0)])\n",
        "        latents = self.encoder.predict(x_test)[0]\n",
        "        Yt_hat = []\n",
        "        for _ in range(nums):\n",
        "            Yt_hat.append(predict_stochastic([latents, 1])) \n",
        "        return np.asarray(Yt_hat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TsARTKz36LQZ"
      },
      "source": [
        "## Train and evaluate Dropout VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pkdmVggK6LQp",
        "outputId": "4402b56f-b0f9-40aa-faea-7a4a48fa7fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3743
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "set_random_seed(1)\n",
        "\n",
        "latent_dim = original_dim//2\n",
        "if latent_dim < 2:\n",
        "    latent_dim = 2\n",
        "vae = DropoutVAE(intermediate_dim=intermediate_dim,\n",
        "                 dropout=0.1, latent_dim=latent_dim,\n",
        "                 summary=True)\n",
        "vae.fit(x_train, x_test, epochs=100)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0616 09:39:46.119600 140490864273280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 47)                0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 23), (None, 23)]  51118     \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 47)                48175     \n",
            "=================================================================\n",
            "Total params: 99,293\n",
            "Trainable params: 99,293\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1760 samples, validate on 1761 samples\n",
            "Epoch 1/100\n",
            "1760/1760 [==============================] - 1s 549us/step - loss: 31.4617 - val_loss: 27.9931\n",
            "Epoch 2/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 24.8969 - val_loss: 21.3847\n",
            "Epoch 3/100\n",
            "1760/1760 [==============================] - 0s 112us/step - loss: 19.6656 - val_loss: 17.8310\n",
            "Epoch 4/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 16.8436 - val_loss: 15.5044\n",
            "Epoch 5/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 14.6668 - val_loss: 13.5206\n",
            "Epoch 6/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 12.8358 - val_loss: 11.7743\n",
            "Epoch 7/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 11.3459 - val_loss: 10.3412\n",
            "Epoch 8/100\n",
            "1760/1760 [==============================] - 0s 116us/step - loss: 10.0502 - val_loss: 9.0639\n",
            "Epoch 9/100\n",
            "1760/1760 [==============================] - 0s 112us/step - loss: 8.9672 - val_loss: 8.1459\n",
            "Epoch 10/100\n",
            "1760/1760 [==============================] - 0s 112us/step - loss: 8.1840 - val_loss: 7.4712\n",
            "Epoch 11/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 7.4909 - val_loss: 6.9077\n",
            "Epoch 12/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 6.9659 - val_loss: 6.2012\n",
            "Epoch 13/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 6.4499 - val_loss: 5.8438\n",
            "Epoch 14/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 6.0930 - val_loss: 5.4847\n",
            "Epoch 15/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 5.7369 - val_loss: 5.1418\n",
            "Epoch 16/100\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 5.4466 - val_loss: 4.9147\n",
            "Epoch 17/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 5.1917 - val_loss: 4.6628\n",
            "Epoch 18/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 4.9472 - val_loss: 4.4245\n",
            "Epoch 19/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 4.7667 - val_loss: 4.3350\n",
            "Epoch 20/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 4.5549 - val_loss: 4.0455\n",
            "Epoch 21/100\n",
            "1760/1760 [==============================] - 0s 113us/step - loss: 4.4246 - val_loss: 3.9332\n",
            "Epoch 22/100\n",
            "1760/1760 [==============================] - 0s 113us/step - loss: 4.2212 - val_loss: 3.7228\n",
            "Epoch 23/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 4.0319 - val_loss: 3.5986\n",
            "Epoch 24/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 3.8778 - val_loss: 3.4254\n",
            "Epoch 25/100\n",
            "1760/1760 [==============================] - 0s 115us/step - loss: 3.7975 - val_loss: 3.3635\n",
            "Epoch 26/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 3.6704 - val_loss: 3.2620\n",
            "Epoch 27/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 3.6093 - val_loss: 3.1905\n",
            "Epoch 28/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 3.4965 - val_loss: 3.0811\n",
            "Epoch 29/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 3.4200 - val_loss: 3.0205\n",
            "Epoch 30/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 3.3419 - val_loss: 2.9639\n",
            "Epoch 31/100\n",
            "1760/1760 [==============================] - 0s 109us/step - loss: 3.2897 - val_loss: 2.9009\n",
            "Epoch 32/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 3.2885 - val_loss: 2.9173\n",
            "Epoch 33/100\n",
            "1760/1760 [==============================] - 0s 109us/step - loss: 3.1371 - val_loss: 2.7704\n",
            "Epoch 34/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 3.0612 - val_loss: 2.7268\n",
            "Epoch 35/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 3.0245 - val_loss: 2.6653\n",
            "Epoch 36/100\n",
            "1760/1760 [==============================] - 0s 113us/step - loss: 2.9853 - val_loss: 2.6351\n",
            "Epoch 37/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 2.9087 - val_loss: 2.5998\n",
            "Epoch 38/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.8661 - val_loss: 2.5509\n",
            "Epoch 39/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 2.8529 - val_loss: 2.5321\n",
            "Epoch 40/100\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 2.7922 - val_loss: 2.4889\n",
            "Epoch 41/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.7573 - val_loss: 2.4722\n",
            "Epoch 42/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.7500 - val_loss: 2.4474\n",
            "Epoch 43/100\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 2.7281 - val_loss: 2.4126\n",
            "Epoch 44/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.6622 - val_loss: 2.4099\n",
            "Epoch 45/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 2.6718 - val_loss: 2.3876\n",
            "Epoch 46/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.6023 - val_loss: 2.3650\n",
            "Epoch 47/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 2.6207 - val_loss: 2.3851\n",
            "Epoch 48/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.6081 - val_loss: 2.3076\n",
            "Epoch 49/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 2.5483 - val_loss: 2.2954\n",
            "Epoch 50/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 2.5399 - val_loss: 2.3061\n",
            "Epoch 51/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 2.5346 - val_loss: 2.3224\n",
            "Epoch 52/100\n",
            "1760/1760 [==============================] - 0s 109us/step - loss: 2.5472 - val_loss: 2.2569\n",
            "Epoch 53/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 2.5303 - val_loss: 2.2303\n",
            "Epoch 54/100\n",
            "1760/1760 [==============================] - 0s 112us/step - loss: 2.4526 - val_loss: 2.2096\n",
            "Epoch 55/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 2.4316 - val_loss: 2.2007\n",
            "Epoch 56/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 2.4242 - val_loss: 2.1837\n",
            "Epoch 57/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.4426 - val_loss: 2.1800\n",
            "Epoch 58/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.4064 - val_loss: 2.1797\n",
            "Epoch 59/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.3781 - val_loss: 2.1702\n",
            "Epoch 60/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.4033 - val_loss: 2.1517\n",
            "Epoch 61/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 2.3683 - val_loss: 2.1412\n",
            "Epoch 62/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.3275 - val_loss: 2.1081\n",
            "Epoch 63/100\n",
            "1760/1760 [==============================] - 0s 123us/step - loss: 2.3318 - val_loss: 2.1144\n",
            "Epoch 64/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 2.3081 - val_loss: 2.0855\n",
            "Epoch 65/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 2.2916 - val_loss: 2.1226\n",
            "Epoch 66/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.2913 - val_loss: 2.1163\n",
            "Epoch 67/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.3008 - val_loss: 2.1059\n",
            "Epoch 68/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.3044 - val_loss: 2.0772\n",
            "Epoch 69/100\n",
            "1760/1760 [==============================] - 0s 109us/step - loss: 2.2878 - val_loss: 2.1108\n",
            "Epoch 70/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.3018 - val_loss: 2.0943\n",
            "Epoch 71/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 2.2516 - val_loss: 2.0521\n",
            "Epoch 72/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.2329 - val_loss: 2.0296\n",
            "Epoch 73/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.2429 - val_loss: 2.0403\n",
            "Epoch 74/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.2162 - val_loss: 2.0325\n",
            "Epoch 75/100\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 2.2037 - val_loss: 2.0185\n",
            "Epoch 76/100\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 2.2137 - val_loss: 2.0347\n",
            "Epoch 77/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.2167 - val_loss: 1.9995\n",
            "Epoch 78/100\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 2.1893 - val_loss: 1.9847\n",
            "Epoch 79/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.1936 - val_loss: 1.9863\n",
            "Epoch 80/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 2.1657 - val_loss: 2.0048\n",
            "Epoch 81/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 2.1781 - val_loss: 1.9707\n",
            "Epoch 82/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.1763 - val_loss: 1.9841\n",
            "Epoch 83/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 2.1416 - val_loss: 1.9760\n",
            "Epoch 84/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 2.1268 - val_loss: 1.9526\n",
            "Epoch 85/100\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 2.1389 - val_loss: 1.9731\n",
            "Epoch 86/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.1464 - val_loss: 1.9866\n",
            "Epoch 87/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.1332 - val_loss: 1.9557\n",
            "Epoch 88/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.1207 - val_loss: 1.9528\n",
            "Epoch 89/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 2.1473 - val_loss: 1.9453\n",
            "Epoch 90/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 2.1202 - val_loss: 1.9634\n",
            "Epoch 91/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.0851 - val_loss: 1.9471\n",
            "Epoch 92/100\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 2.1032 - val_loss: 1.9247\n",
            "Epoch 93/100\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 2.1029 - val_loss: 1.9160\n",
            "Epoch 94/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 2.0673 - val_loss: 1.9181\n",
            "Epoch 95/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 2.0761 - val_loss: 1.9256\n",
            "Epoch 96/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 2.0414 - val_loss: 1.9017\n",
            "Epoch 97/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 2.0827 - val_loss: 1.9008\n",
            "Epoch 98/100\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 2.0564 - val_loss: 1.9017\n",
            "Epoch 99/100\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 2.0836 - val_loss: 1.9027\n",
            "Epoch 100/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 2.0543 - val_loss: 1.8848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2HndA3MG6LQs",
        "outputId": "96e937b3-e76e-4712-c649-e53ef0d97439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x_test = np.reshape(x_test, (-1, original_dim))\n",
        "print(x_test.shape)\n",
        "print(x_test[0].reshape(-1, original_dim).shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1761, 47)\n",
            "(1, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sgO9JKSqWsW",
        "colab_type": "code",
        "outputId": "94ebe509-31e1-4806-de87-0098810afb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import time\n",
        "np.random.seed(1)\n",
        "set_random_seed(1)\n",
        "start = time.time()\n",
        "total_nums = 2\n",
        "results = []\n",
        "x_test_encoded = vae.mean_predict(x_test, nums=total_nums, batch_size=100)\n",
        "results = x_test_encoded\n",
        "results = np.asarray(results)\n",
        "print(results.shape)\n",
        "results = results.reshape(total_nums*results.shape[2], original_dim)\n",
        "results = scaler.inverse_transform(results)\n",
        "print(results.shape)\n",
        "end = time.time()\n",
        "print('Total time=', end-start)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 1, 1761, 47)\n",
            "(3522, 47)\n",
            "Total time= 0.20811104774475098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POfJxgHamlmx",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YIlGSzekAYlO",
        "colab": {}
      },
      "source": [
        "d = {}\n",
        "names = list(df)\n",
        "for i, name in enumerate(names):\n",
        "    d[name] = results[:, i]\n",
        "df = pd.DataFrame(data=d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4f17fd64-e9d7-46b3-fc6b-ee8a777dd89f",
        "id": "shurAQCSAYlV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "names = list(df)\n",
        "c_dict = {}\n",
        "for n in names:\n",
        "    if '_' in n:\n",
        "        index = n.index('_')\n",
        "        c_dict[n[:index]] = [c for c in names if n[:index+1] in c]\n",
        "values = []\n",
        "for key, items in c_dict.items():\n",
        "    dummies = df[items]\n",
        "    d_names = list(dummies)\n",
        "    c_dict = {}\n",
        "    for n in d_names:\n",
        "        c_dict[n] = n[n.index('_')+1:]\n",
        "    dummies.rename(columns=c_dict, \n",
        "                   inplace=True)\n",
        "    df[key] = dummies.idxmax(axis=1)\n",
        "    df.drop(items, axis=1, inplace=True)\n",
        "print(df.head())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   SeniorCitizen     tenure  ...              PaymentMethod  Churn\n",
            "0       0.999540  32.267971  ...  Bank transfer (automatic)     No\n",
            "1       0.004290  69.549248  ...    Credit card (automatic)     No\n",
            "2       0.999360   2.502510  ...           Electronic check    Yes\n",
            "3       0.978087   1.441715  ...           Electronic check    Yes\n",
            "4       0.000853  15.524832  ...  Bank transfer (automatic)    Yes\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8dLIoyVW_Kn",
        "colab": {}
      },
      "source": [
        "df = df.reindex(sorted(df.columns), axis=1)\n",
        "df.to_csv(path + '_dropout.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL6N8v2sYTNm",
        "colab_type": "text"
      },
      "source": [
        "# Transform categorical -> number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgVhmliYYzwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "validation.to_csv(path + '_For_Test.csv')\n",
        "df = pd.read_csv(path + '_For_Test.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df_mc = pd.read_csv(path + '_dropout.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df_vae = pd.read_csv(path + '_vae.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_mc.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_vae.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "names = list(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSbyWbb0ZjAJ",
        "colab_type": "code",
        "outputId": "c120b248-d395-406b-fb27-9f05ac3ed6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "colnums = len(df.columns)\n",
        "for i in df.columns:\n",
        "    try:\n",
        "        if df[i].dtype.name == 'object':\n",
        "            df[i] = df[i].astype('category')\n",
        "    except:\n",
        "        continue\n",
        "cat_columns = df.select_dtypes(['category']).columns\n",
        "print(cat_columns)\n",
        "for col in cat_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].values)\n",
        "    df_mc[col] = le.transform(df_mc[col].values)\n",
        "    df_vae[col] = le.transform(df_vae[col].values)\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Churn', 'Contract', 'Dependents', 'DeviceProtection',\n",
            "       'InternetService', 'MultipleLines', 'OnlineBackup', 'OnlineSecurity',\n",
            "       'PaperlessBilling', 'Partner', 'PaymentMethod', 'PhoneService',\n",
            "       'StreamingMovies', 'StreamingTV', 'TechSupport', 'gender'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-scTKTHZ9Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reindex(sorted(df.columns), axis=1)\n",
        "df_mc = df_mc.reindex(sorted(df_mc.columns), axis=1)\n",
        "df_vae = df_vae.reindex(sorted(df_vae.columns), axis=1)\n",
        "df.to_csv(path + '_For_Test_encoded.csv')\n",
        "df_mc.to_csv(path + '_dropout_encoded.csv')\n",
        "df_vae.to_csv(path + '_vae_encoded.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLy-z65OUnRj",
        "colab_type": "text"
      },
      "source": [
        "# Predicting with generated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W-tX8ysUuOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(path + '_For_Test_encoded.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df_mc = pd.read_csv(path + '_dropout_encoded.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df_vae = pd.read_csv(path + '_vae_encoded.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_mc.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_vae.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F40hUKFVC3E",
        "colab_type": "code",
        "outputId": "868e331b-d5f4-456c-fa1e-c1100b18363a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "print(df.head())\n",
        "print(df_mc.head())\n",
        "print(df_vae.head())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Churn  Contract  Dependents  ...  TotalCharges  gender  tenure\n",
            "0      1         0           0  ...         24.80       0       1\n",
            "1      0         0           0  ...        996.45       1      41\n",
            "2      0         2           1  ...       1031.70       0      52\n",
            "3      1         0           0  ...         76.35       0       1\n",
            "4      0         2           0  ...       3260.10       1      67\n",
            "\n",
            "[5 rows x 20 columns]\n",
            "   Churn  Contract  Dependents  ...  TotalCharges  gender     tenure\n",
            "0      0         0           0  ...   1667.326000       0  32.267970\n",
            "1      0         2           0  ...   7096.594700       0  69.549250\n",
            "2      1         0           0  ...    241.495640       0   2.502510\n",
            "3      1         0           0  ...    124.694466       1   1.441715\n",
            "4      1         0           0  ...   1836.468300       0  15.524832\n",
            "\n",
            "[5 rows x 20 columns]\n",
            "   Churn  Contract  Dependents  ...  TotalCharges  gender     tenure\n",
            "0      0         1           0  ...    3864.59250       0  37.876163\n",
            "1      0         0           0  ...    2734.44700       0  34.850628\n",
            "2      0         2           0  ...    6478.32470       0  62.554085\n",
            "3      0         2           0  ...    6044.22900       0  64.294090\n",
            "4      1         0           0  ...     367.57507       0   5.142932\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tyhyfWHXbn4",
        "colab_type": "code",
        "outputId": "3d7fd433-154f-4ec9-c735-9dd979ac84c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y = df['Churn'].values\n",
        "df.drop(['Churn'], axis=1, inplace=True)\n",
        "X = df.values\n",
        "print(y.shape)\n",
        "print(X.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3522,)\n",
            "(3522, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwzr1m5TX5QC",
        "colab_type": "code",
        "outputId": "39d6ca89-2020-4aed-e167-edf6e3b32302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_mc = df_mc['Churn'].values\n",
        "df_mc.drop(['Churn'], axis=1, inplace=True)\n",
        "X_mc = df_mc.values\n",
        "print(y_mc.shape)\n",
        "print(X_mc.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3522,)\n",
            "(3522, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbq6H2ZnYXqz",
        "colab_type": "code",
        "outputId": "74692b43-eaef-4c76-ed92-8f85ea7788d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_vae = df_vae['Churn'].values\n",
        "df_vae.drop(['Churn'], axis=1, inplace=True)\n",
        "X_vae = df_vae.values\n",
        "print(y_vae.shape)\n",
        "print(X_vae.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3522,)\n",
            "(3522, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWMcVL29ggWg",
        "colab_type": "text"
      },
      "source": [
        "### Original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob3Et0uia9YZ",
        "colab_type": "code",
        "outputId": "37a8a4ef-07d8-45a5-a26e-62fbd971b139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "scores = cross_val_score(clf, X, y, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.77 (+/- 0.03)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ySOOpbfD5RP1",
        "outputId": "0e0625ea-e349-4182-8105-9061b2db55e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "scores = cross_val_score(clf, X_mc, y_mc, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.79 (+/- 0.02)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lycl8s_A5Vxf",
        "outputId": "c8a38e16-2442-4873-969f-d24286470ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "scores = cross_val_score(clf, X_vae, y_vae, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), \n",
        "                                       scores.std() * 2))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.79 (+/- 0.03)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hSUz0c0ngkj5"
      },
      "source": [
        "### DropoutVAE generated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y4-GzQ_bbPCo",
        "outputId": "4bd608e5-9042-48bc-fba3-adff537b221c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "clf.fit(X_mc, y_mc)\n",
        "print(clf.score(X, y))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7825099375354913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NL3OtgaGgxQB"
      },
      "source": [
        "### VAE generated data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crz0AfZ-bSg-",
        "colab_type": "code",
        "outputId": "1ba2015d-d893-4b8d-9e6e-97b570b14300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "clf.fit(X_vae, y_vae)\n",
        "print(clf.score(X, y))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7481544576944917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mrCqDtssg4nB"
      },
      "source": [
        "### Original data with Dropout VAE outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mH3gS3nacvV7",
        "outputId": "1af32f59-80e2-4397-c3b0-2257d0145b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "clf.fit(X, y)\n",
        "print(clf.score(X_mc, y_mc))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7703009653605906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YlER2gGnhBGJ"
      },
      "source": [
        "### Original data with VAE outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MezW_-9ZcvWA",
        "outputId": "2bd60e48-8253-409c-ca06-51f8a2c904c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "clf.fit(X, y)\n",
        "print(clf.score(X_vae, y_vae))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7887563884156729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCm6BBN1zB-0",
        "colab_type": "code",
        "outputId": "1be2c881-9bd9-4ce5-843a-c388e91f4a98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "clf.fit(X_mc, y_mc)\n",
        "print(clf.score(X_vae, y_vae))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7941510505394662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XcarR61z4UqD",
        "outputId": "3d661cf2-eb9a-4d8f-be9d-ff7f9bdb4fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "clf.fit(X_vae, y_vae)\n",
        "print(clf.score(X_mc, y_mc))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7438955139125497\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}