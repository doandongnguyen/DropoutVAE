{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DropoutVAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl5YDWvEeu4a",
        "colab_type": "text"
      },
      "source": [
        "The purpose is to use Dropout in VAE in order to generate data.\n",
        "\n",
        "Origin VAE uses latent values to generate the data.\n",
        "However, with Dropout VAE, we can use some origin data to generate.\n",
        "\n",
        "\n",
        "The dataset used in notebook: [Customer Support](https://www.ibm.com/communities/analytics/watson-analytics-blog/guide-to-sample-datasets/)\n",
        "\n",
        "More example about VAE: [Modeling Telecom customer churn](https://towardsdatascience.com/modeling-telecom-customer-churn-with-variational-autoencoder-4e5cf6194871)\n",
        "\n",
        "Origin code for VAE in keras: [Building Autoencoders in keras](https://blog.keras.io/building-autoencoders-in-keras.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdT9BTrmT3ro",
        "colab_type": "text"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNUpL6YT32X",
        "colab_type": "code",
        "outputId": "139b3816-79dc-4879-c80b-3b731be124fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow import set_random_seed\n",
        "\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "from keras.losses import mse, binary_crossentropy\n",
        "from keras.layers import Lambda, Input, Dense, Dropout\n",
        "\n",
        "set_random_seed(1)\n",
        "np.random.seed(1)\n",
        "random.seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNKVLBOBgR3W",
        "colab_type": "text"
      },
      "source": [
        "# Path to dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFaXts2Ycg-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'gdrive/My Drive/Dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8zWTy_ePGg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "intermediate_dim = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnJXo9LfUGaJ",
        "colab_type": "text"
      },
      "source": [
        "# Define VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VTGWwfObeoT",
        "colab_type": "text"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfcE15dwhyaL",
        "colab_type": "code",
        "outputId": "4a2d02d1-7d04-4867-a2ce-5a60b60f27af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import pandas as pd\n",
        "na_values = {'?', ' '}\n",
        "df = pd.read_csv(path,\n",
        "                 sep=',',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "                 \n",
        "df.fillna(method='ffill', inplace=True)\n",
        "df.dropna(axis=1, how='any', inplace=True)\n",
        "df.drop(['customerID'], axis=1, inplace=True)\n",
        "df = df.reset_index(drop=True)\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 20 columns):\n",
            "gender              7043 non-null object\n",
            "SeniorCitizen       7043 non-null int64\n",
            "Partner             7043 non-null object\n",
            "Dependents          7043 non-null object\n",
            "tenure              7043 non-null int64\n",
            "PhoneService        7043 non-null object\n",
            "MultipleLines       7043 non-null object\n",
            "InternetService     7043 non-null object\n",
            "OnlineSecurity      7043 non-null object\n",
            "OnlineBackup        7043 non-null object\n",
            "DeviceProtection    7043 non-null object\n",
            "TechSupport         7043 non-null object\n",
            "StreamingTV         7043 non-null object\n",
            "StreamingMovies     7043 non-null object\n",
            "Contract            7043 non-null object\n",
            "PaperlessBilling    7043 non-null object\n",
            "PaymentMethod       7043 non-null object\n",
            "MonthlyCharges      7043 non-null float64\n",
            "TotalCharges        7043 non-null float64\n",
            "Churn               7043 non-null object\n",
            "dtypes: float64(2), int64(2), object(16)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "   gender  SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n",
            "0  Female              0     Yes  ...          29.85         29.85    No\n",
            "1    Male              0      No  ...          56.95       1889.50    No\n",
            "2    Male              0      No  ...          53.85        108.15   Yes\n",
            "3    Male              0      No  ...          42.30       1840.75    No\n",
            "4  Female              0      No  ...          70.70        151.65   Yes\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptmiXDEjbhmp",
        "colab_type": "text"
      },
      "source": [
        "## Recognizing Categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfL6yO7HZR7E",
        "colab_type": "code",
        "outputId": "69f9f99c-c9a6-4f57-99bf-58dce5c53edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "colnums = len(df.columns)\n",
        "for i in df.columns:\n",
        "    try:\n",
        "        if df[i].dtype.name == 'object':\n",
        "            df[i] = df[i].astype('category')\n",
        "        else:\n",
        "            df[i].astype('float32')\n",
        "    except:\n",
        "        continue\n",
        "print(df.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   gender  SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n",
            "0  Female              0     Yes  ...          29.85         29.85    No\n",
            "1    Male              0      No  ...          56.95       1889.50    No\n",
            "2    Male              0      No  ...          53.85        108.15   Yes\n",
            "3    Male              0      No  ...          42.30       1840.75    No\n",
            "4  Female              0      No  ...          70.70        151.65   Yes\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpGxC2v2CDi1",
        "colab_type": "code",
        "outputId": "0d69172e-cd90-41db-fa73-ce8237c36208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "vals = df.values.copy()\n",
        "total_nums = len(vals)\n",
        "\n",
        "train, validation = train_test_split(df, test_size=0.5, \n",
        "                                     random_state=42, \n",
        "                                     shuffle=True)\n",
        "\n",
        "validation = validation.reindex(sorted(validation.columns), axis=1)\n",
        "validation.to_csv(path + '_For_Test.csv')\n",
        "print(validation.head())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Churn        Contract Dependents  ... TotalCharges  gender  tenure\n",
            "185    Yes  Month-to-month         No  ...        24.80  Female       1\n",
            "2715    No  Month-to-month         No  ...       996.45    Male      41\n",
            "3825    No        Two year        Yes  ...      1031.70  Female      52\n",
            "1807   Yes  Month-to-month         No  ...        76.35  Female       1\n",
            "132     No        Two year         No  ...      3260.10    Male      67\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-52cnSrZHGm",
        "colab_type": "code",
        "outputId": "7055b2bd-42e8-473b-e0fa-62e81ac7674b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df = train\n",
        "categorical = df.select_dtypes(['category']).columns\n",
        "print(categorical)\n",
        "for f in categorical:\n",
        "    dummies = pd.get_dummies(df[f], prefix = f, prefix_sep = '_')\n",
        "    df = pd.concat([df, dummies], axis = 1)\n",
        "    \n",
        "# drop original categorical features\n",
        "df.drop(categorical, axis = 1, inplace = True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
            "       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
            "       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
            "       'PaperlessBilling', 'PaymentMethod', 'Churn'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmIPmd5wjAM7",
        "colab_type": "code",
        "outputId": "a86ba7c5-0c35-4b20-b776-1eb6ff4d725b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train = df.values.copy()\n",
        "train.astype('float32')\n",
        "scaler = MinMaxScaler()\n",
        "d = {}\n",
        "train = scaler.fit_transform(train)\n",
        "x_train, x_test = train_test_split(train, test_size=0.5,\n",
        "                                  random_state=24,\n",
        "                                  shuffle=True)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1760, 47)\n",
            "(1761, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNf-3EMl2usm",
        "colab_type": "code",
        "outputId": "e7808a07-3810-440f-a372-fc7e9afe1d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "original_dim = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, original_dim])\n",
        "x_test = np.reshape(x_test, [-1, original_dim])\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1760, 47)\n",
            "(1761, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy-JqW7Jpuyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import BatchNormalization\n",
        "class VAE:\n",
        "    def __init__(self, input_shape=(original_dim,), \n",
        "                 intermediate_dim=128, latent_dim=2, summary=False):\n",
        "        \n",
        "        self._build_model(input_shape,\n",
        "                         intermediate_dim, \n",
        "                          latent_dim, summary)\n",
        "    \n",
        "    def _build_model(self, input_shape, intermediate_dim, latent_dim,\n",
        "                    summary=False):\n",
        "        inputs = Input(shape=input_shape, name='encoder_input')\n",
        "        x = inputs\n",
        "        x = Dense(intermediate_dim, activation='relu')(x)\n",
        "        x = Dense(intermediate_dim//2, activation='relu')(x)\n",
        "        \n",
        "        z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "        z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "        z = Lambda(self.sampling, output_shape=(latent_dim,), \n",
        "                   name='z')([z_mean, z_log_var])\n",
        "\n",
        "        self.encoder = Model(inputs, [z_mean, z_log_var, z], \n",
        "                        name='encoder')\n",
        "        \n",
        "        latent_inputs = Input(shape=(latent_dim,), \n",
        "                              name='z_sampling')\n",
        "        x = latent_inputs\n",
        "        x = Dense(intermediate_dim//2, activation='relu')(x)\n",
        "        x = Dense(intermediate_dim, activation='relu')(x)\n",
        "        outputs = Dense(original_dim, activation='sigmoid')(x)\n",
        "\n",
        "        self.decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "        outputs = self.decoder(self.encoder(inputs)[2])\n",
        "        self.vae = Model(inputs, outputs, name='vae_mlp')\n",
        "        \n",
        "        reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
        "        reconstruction_loss *= original_dim\n",
        "        kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "        kl_loss = K.sum(kl_loss, axis=-1)\n",
        "        kl_loss *= -0.5\n",
        "        \n",
        "        vae_loss = K.mean(reconstruction_loss + kl_loss)\t\n",
        "        \n",
        "        self.vae.add_loss(vae_loss)\n",
        "        self.vae.compile(optimizer='adam')\n",
        "        if summary: \n",
        "            print(self.vae.summary())\n",
        "        \n",
        "    def sampling(self, args):\n",
        "        z_mean, z_log_var = args\n",
        "        batch = K.shape(z_mean)[0]\n",
        "        dim = K.int_shape(z_mean)[1]\n",
        "        epsilon = K.random_normal(shape=(batch, dim))\n",
        "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "        \n",
        "    def fit(self, x_train, x_test, epochs=100, batch_size=100,\n",
        "           verbose=1):\n",
        "        self.vae.fit(x_train, \n",
        "            shuffle=True,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            verbose=verbose,\n",
        "            validation_data=(x_test, None))\n",
        "    \n",
        "    def encoder_predict(self, x_test, batch_size=100):\n",
        "        return self.encoder.predict(x_test,\n",
        "                                   batch_size=batch_size)\n",
        "    \n",
        "    def generate(self, latent_val, batch_size=100):\n",
        "        return self.decoder.predict(latent_val)\n",
        "    \n",
        "    def predict(self, x_test, batch_size=1):\n",
        "        prediction = self.vae.predict(x_test)\n",
        "        return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXhRjx02UYZN",
        "colab_type": "text"
      },
      "source": [
        "## Training VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd02caRJWGG8",
        "colab_type": "text"
      },
      "source": [
        "Just let the last value to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBbIF17p8iY2",
        "colab_type": "code",
        "outputId": "f83a7c8c-6be6-4904-9f52-1a3fa4cde58e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5256
        }
      },
      "source": [
        "latent_dim = original_dim//2\n",
        "if latent_dim < 2:\n",
        "    latent_dim = 2\n",
        "vae = VAE(intermediate_dim=intermediate_dim, latent_dim=latent_dim)\n",
        "vae.fit(x_train, x_test, epochs=150)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 1760 samples, validate on 1761 samples\n",
            "Epoch 1/150\n",
            "1760/1760 [==============================] - 1s 771us/step - loss: 29.3855 - val_loss: 28.3879\n",
            "Epoch 2/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 27.7459 - val_loss: 26.8112\n",
            "Epoch 3/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 24.9679 - val_loss: 23.5514\n",
            "Epoch 4/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 23.0151 - val_loss: 22.8142\n",
            "Epoch 5/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 22.5863 - val_loss: 22.2015\n",
            "Epoch 6/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 21.8968 - val_loss: 21.6563\n",
            "Epoch 7/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 21.7712 - val_loss: 21.4705\n",
            "Epoch 8/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 21.5398 - val_loss: 21.4014\n",
            "Epoch 9/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 21.1764 - val_loss: 20.9156\n",
            "Epoch 10/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 20.9328 - val_loss: 20.8186\n",
            "Epoch 11/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 20.7545 - val_loss: 20.5236\n",
            "Epoch 12/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 20.3516 - val_loss: 20.1582\n",
            "Epoch 13/150\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 20.0311 - val_loss: 19.8309\n",
            "Epoch 14/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 19.8049 - val_loss: 19.6918\n",
            "Epoch 15/150\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 19.5912 - val_loss: 19.4149\n",
            "Epoch 16/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 19.3916 - val_loss: 19.2297\n",
            "Epoch 17/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 19.1656 - val_loss: 19.2349\n",
            "Epoch 18/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 18.9616 - val_loss: 18.9263\n",
            "Epoch 19/150\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 18.9675 - val_loss: 19.0004\n",
            "Epoch 20/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 18.9471 - val_loss: 18.9325\n",
            "Epoch 21/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 18.7960 - val_loss: 18.6618\n",
            "Epoch 22/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 18.4087 - val_loss: 18.5157\n",
            "Epoch 23/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 18.5622 - val_loss: 18.5174\n",
            "Epoch 24/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 18.3025 - val_loss: 18.3819\n",
            "Epoch 25/150\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 18.4338 - val_loss: 18.4708\n",
            "Epoch 26/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 18.1345 - val_loss: 18.3815\n",
            "Epoch 27/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 18.0502 - val_loss: 18.2081\n",
            "Epoch 28/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 17.7580 - val_loss: 18.0244\n",
            "Epoch 29/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 17.8463 - val_loss: 17.9728\n",
            "Epoch 30/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 17.6960 - val_loss: 17.8693\n",
            "Epoch 31/150\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 17.5191 - val_loss: 17.7644\n",
            "Epoch 32/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 17.5724 - val_loss: 17.6205\n",
            "Epoch 33/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 17.4707 - val_loss: 17.5080\n",
            "Epoch 34/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 17.4694 - val_loss: 17.7645\n",
            "Epoch 35/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 17.5074 - val_loss: 17.6011\n",
            "Epoch 36/150\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 17.2092 - val_loss: 17.4293\n",
            "Epoch 37/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 17.0919 - val_loss: 17.1934\n",
            "Epoch 38/150\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 17.1590 - val_loss: 17.2023\n",
            "Epoch 39/150\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 16.9236 - val_loss: 17.3725\n",
            "Epoch 40/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.9548 - val_loss: 17.1094\n",
            "Epoch 41/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 16.9069 - val_loss: 17.3923\n",
            "Epoch 42/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.7613 - val_loss: 17.1973\n",
            "Epoch 43/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 16.7964 - val_loss: 17.0329\n",
            "Epoch 44/150\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 16.8411 - val_loss: 17.0459\n",
            "Epoch 45/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 16.5601 - val_loss: 16.9341\n",
            "Epoch 46/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.6564 - val_loss: 16.9974\n",
            "Epoch 47/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.6170 - val_loss: 16.9592\n",
            "Epoch 48/150\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 16.5006 - val_loss: 17.0596\n",
            "Epoch 49/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.7437 - val_loss: 17.0365\n",
            "Epoch 50/150\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 16.5645 - val_loss: 17.0381\n",
            "Epoch 51/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 16.5518 - val_loss: 17.1466\n",
            "Epoch 52/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.5552 - val_loss: 16.9547\n",
            "Epoch 53/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 16.4701 - val_loss: 16.8594\n",
            "Epoch 54/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.3614 - val_loss: 16.7707\n",
            "Epoch 55/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 16.4250 - val_loss: 16.8005\n",
            "Epoch 56/150\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 16.2960 - val_loss: 16.7322\n",
            "Epoch 57/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.5483 - val_loss: 16.8956\n",
            "Epoch 58/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.1062 - val_loss: 16.5712\n",
            "Epoch 59/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.1549 - val_loss: 16.5295\n",
            "Epoch 60/150\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 16.2754 - val_loss: 16.5081\n",
            "Epoch 61/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 16.1846 - val_loss: 16.7470\n",
            "Epoch 62/150\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 16.0605 - val_loss: 16.6460\n",
            "Epoch 63/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.1466 - val_loss: 16.6958\n",
            "Epoch 64/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.2117 - val_loss: 16.5983\n",
            "Epoch 65/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 16.0337 - val_loss: 16.5329\n",
            "Epoch 66/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.1757 - val_loss: 16.5803\n",
            "Epoch 67/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.1612 - val_loss: 16.4554\n",
            "Epoch 68/150\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 16.2620 - val_loss: 16.5133\n",
            "Epoch 69/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.9698 - val_loss: 16.7100\n",
            "Epoch 70/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 16.1314 - val_loss: 16.4625\n",
            "Epoch 71/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.9731 - val_loss: 16.4275\n",
            "Epoch 72/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.0481 - val_loss: 16.6932\n",
            "Epoch 73/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.8710 - val_loss: 16.4166\n",
            "Epoch 74/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 16.0408 - val_loss: 16.2490\n",
            "Epoch 75/150\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 16.0692 - val_loss: 16.5335\n",
            "Epoch 76/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.2664 - val_loss: 16.5199\n",
            "Epoch 77/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.8919 - val_loss: 16.4166\n",
            "Epoch 78/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.9286 - val_loss: 16.5717\n",
            "Epoch 79/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 15.8490 - val_loss: 16.4987\n",
            "Epoch 80/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 16.1663 - val_loss: 16.3749\n",
            "Epoch 81/150\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 15.9313 - val_loss: 16.5615\n",
            "Epoch 82/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 16.0287 - val_loss: 16.4268\n",
            "Epoch 83/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.7589 - val_loss: 16.0962\n",
            "Epoch 84/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.7601 - val_loss: 16.3620\n",
            "Epoch 85/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.9095 - val_loss: 16.1092\n",
            "Epoch 86/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.6176 - val_loss: 16.1157\n",
            "Epoch 87/150\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 15.5878 - val_loss: 16.3787\n",
            "Epoch 88/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.6503 - val_loss: 16.2261\n",
            "Epoch 89/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.7469 - val_loss: 16.3302\n",
            "Epoch 90/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 15.7826 - val_loss: 16.3644\n",
            "Epoch 91/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.9112 - val_loss: 16.3657\n",
            "Epoch 92/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.5594 - val_loss: 16.1437\n",
            "Epoch 93/150\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 15.8074 - val_loss: 16.1856\n",
            "Epoch 94/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.7038 - val_loss: 16.2355\n",
            "Epoch 95/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.6578 - val_loss: 16.2146\n",
            "Epoch 96/150\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 15.6700 - val_loss: 16.4576\n",
            "Epoch 97/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.7815 - val_loss: 16.3618\n",
            "Epoch 98/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.6653 - val_loss: 16.5937\n",
            "Epoch 99/150\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 15.7764 - val_loss: 16.4729\n",
            "Epoch 100/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.6757 - val_loss: 16.3842\n",
            "Epoch 101/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.7438 - val_loss: 15.9810\n",
            "Epoch 102/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.6496 - val_loss: 16.1739\n",
            "Epoch 103/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.5473 - val_loss: 16.0415\n",
            "Epoch 104/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.6291 - val_loss: 16.0072\n",
            "Epoch 105/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 15.5473 - val_loss: 16.1881\n",
            "Epoch 106/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.6084 - val_loss: 16.2045\n",
            "Epoch 107/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.5756 - val_loss: 15.9445\n",
            "Epoch 108/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.3821 - val_loss: 16.0805\n",
            "Epoch 109/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 15.4874 - val_loss: 16.0864\n",
            "Epoch 110/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.5846 - val_loss: 16.1268\n",
            "Epoch 111/150\n",
            "1760/1760 [==============================] - 0s 91us/step - loss: 15.3950 - val_loss: 16.1302\n",
            "Epoch 112/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 15.5027 - val_loss: 16.0316\n",
            "Epoch 113/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.2897 - val_loss: 16.0089\n",
            "Epoch 114/150\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 15.3213 - val_loss: 16.1515\n",
            "Epoch 115/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.5015 - val_loss: 15.8853\n",
            "Epoch 116/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.4119 - val_loss: 15.8524\n",
            "Epoch 117/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.4089 - val_loss: 16.0738\n",
            "Epoch 118/150\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 15.5558 - val_loss: 16.0378\n",
            "Epoch 119/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.5039 - val_loss: 16.0302\n",
            "Epoch 120/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.3554 - val_loss: 15.9899\n",
            "Epoch 121/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.3672 - val_loss: 16.0645\n",
            "Epoch 122/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.3505 - val_loss: 16.0056\n",
            "Epoch 123/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.1127 - val_loss: 16.1154\n",
            "Epoch 124/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 15.3719 - val_loss: 15.8538\n",
            "Epoch 125/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.2662 - val_loss: 15.9141\n",
            "Epoch 126/150\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 15.4670 - val_loss: 15.9018\n",
            "Epoch 127/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.2966 - val_loss: 16.0079\n",
            "Epoch 128/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.4118 - val_loss: 15.8735\n",
            "Epoch 129/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.2872 - val_loss: 16.0470\n",
            "Epoch 130/150\n",
            "1760/1760 [==============================] - 0s 96us/step - loss: 15.2254 - val_loss: 15.8541\n",
            "Epoch 131/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.2676 - val_loss: 15.8536\n",
            "Epoch 132/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.1960 - val_loss: 15.8034\n",
            "Epoch 133/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.2722 - val_loss: 16.0910\n",
            "Epoch 134/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.4309 - val_loss: 15.9691\n",
            "Epoch 135/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.2064 - val_loss: 15.8400\n",
            "Epoch 136/150\n",
            "1760/1760 [==============================] - 0s 97us/step - loss: 15.3357 - val_loss: 15.8878\n",
            "Epoch 137/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.1737 - val_loss: 15.9576\n",
            "Epoch 138/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.2838 - val_loss: 16.1550\n",
            "Epoch 139/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.3608 - val_loss: 15.8549\n",
            "Epoch 140/150\n",
            "1760/1760 [==============================] - 0s 92us/step - loss: 15.3102 - val_loss: 15.8872\n",
            "Epoch 141/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.2802 - val_loss: 15.8779\n",
            "Epoch 142/150\n",
            "1760/1760 [==============================] - 0s 99us/step - loss: 15.1953 - val_loss: 15.7830\n",
            "Epoch 143/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.2060 - val_loss: 15.9981\n",
            "Epoch 144/150\n",
            "1760/1760 [==============================] - 0s 95us/step - loss: 15.2368 - val_loss: 15.8975\n",
            "Epoch 145/150\n",
            "1760/1760 [==============================] - 0s 93us/step - loss: 15.2941 - val_loss: 16.0711\n",
            "Epoch 146/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.2771 - val_loss: 15.6370\n",
            "Epoch 147/150\n",
            "1760/1760 [==============================] - 0s 90us/step - loss: 15.0598 - val_loss: 15.8561\n",
            "Epoch 148/150\n",
            "1760/1760 [==============================] - 0s 98us/step - loss: 15.0617 - val_loss: 15.9214\n",
            "Epoch 149/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.0978 - val_loss: 15.9384\n",
            "Epoch 150/150\n",
            "1760/1760 [==============================] - 0s 94us/step - loss: 15.1812 - val_loss: 16.0059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiV2iQyVwSdN",
        "colab_type": "code",
        "outputId": "6e2ec121-efa5-48db-f7d0-50dafc30241f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x_test = np.reshape(x_test, (-1, original_dim))\n",
        "x_test_encoded = vae.encoder.predict(x_test)\n",
        "x_test_encoded = np.asarray(x_test_encoded)\n",
        "\n",
        "print(x_test_encoded.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 1761, 23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTfvSN_R2c76",
        "colab_type": "code",
        "outputId": "3d9a3866-8ed1-4525-cc22-2e1fb9d58038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_nums = 2\n",
        "results = []\n",
        "for i in range(x_test_encoded.shape[1]):\n",
        "    latent_gen = []\n",
        "    for j in range(x_test_encoded.shape[2]):\n",
        "        mean_v1 = x_test_encoded[0, i, j]\n",
        "        log_var_v1 = x_test_encoded[1, i, j]\n",
        "\n",
        "        v1 = [mean_v1 + np.exp(log_var_v1/2)*np.random.normal(0., 1., 1) for _ in range(total_nums)]\n",
        "        v1 = np.asarray(v1).flatten()\n",
        "        latent_gen.append(v1)\n",
        "    \n",
        "    input_val = np.asarray(latent_gen)\n",
        "    input_val = input_val.reshape((-1, latent_dim))\n",
        "    results.append(vae.generate(input_val))\n",
        "        \n",
        "results = np.asarray(results)\n",
        "results = np.reshape(results, (-1, original_dim))\n",
        "print(results.shape)\n",
        "results = scaler.inverse_transform(results)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3522, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdg-w-3eMquu",
        "colab_type": "code",
        "outputId": "475d7a0c-a502-4292-cbbd-a76acfe322a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(results[:, 1]))\n",
        "print(results[0, 0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3522\n",
            "0.09987816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC6DiGV8MV9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {}\n",
        "names = list(df)\n",
        "for i, name in enumerate(names):\n",
        "    d[name] = results[:, i]\n",
        "df = pd.DataFrame(data=d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49_bbWWCsrHG",
        "colab_type": "code",
        "outputId": "57b1ddf8-bd8f-43bb-a827-3c7a37a17f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "names = list(df)\n",
        "c_dict = {}\n",
        "for n in names:\n",
        "    if '_' in n:\n",
        "        index = n.index('_')\n",
        "        c_dict[n[:index]] = [c for c in names if n[:index+1] in c]\n",
        "values = []\n",
        "for key, items in c_dict.items():\n",
        "    dummies = df[items]\n",
        "    d_names = list(dummies)\n",
        "    c_dict = {}\n",
        "    for n in d_names:\n",
        "        c_dict[n] = n[n.index('_')+1:]\n",
        "    dummies.rename(columns=c_dict, \n",
        "                   inplace=True)\n",
        "    df[key] = dummies.idxmax(axis=1)\n",
        "    df.drop(items, axis=1, inplace=True)\n",
        "print(df.head())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   SeniorCitizen     tenure  ...              PaymentMethod  Churn\n",
            "0       0.099878  23.335747  ...           Electronic check     No\n",
            "1       0.030517   6.956230  ...           Electronic check    Yes\n",
            "2       0.087424   7.282513  ...           Electronic check    Yes\n",
            "3       0.154609  29.835083  ...  Bank transfer (automatic)    Yes\n",
            "4       0.041590  27.078154  ...               Mailed check     No\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ljK-ceANBih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reindex(sorted(df.columns), axis=1)\n",
        "df.to_csv(path + '_vae.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SZr05ADu6LQP"
      },
      "source": [
        "# Dropout VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "70nAVW82oNMV"
      },
      "source": [
        "## Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4f3cb175-780e-4ac3-b991-26cc19485639",
        "id": "EUDQdDxxT29T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "import pandas as pd\n",
        "na_values = {'?', ' '}\n",
        "df = pd.read_csv(path,\n",
        "                 sep=',',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "                 \n",
        "df.fillna(method='ffill', inplace=True)\n",
        "df.dropna(axis=1, how='any', inplace=True)\n",
        "df.drop(['customerID'], axis=1, inplace=True)\n",
        "df = df.reset_index(drop=True)\n",
        "print(df.info())\n",
        "print(df.head())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7043 entries, 0 to 7042\n",
            "Data columns (total 20 columns):\n",
            "gender              7043 non-null object\n",
            "SeniorCitizen       7043 non-null int64\n",
            "Partner             7043 non-null object\n",
            "Dependents          7043 non-null object\n",
            "tenure              7043 non-null int64\n",
            "PhoneService        7043 non-null object\n",
            "MultipleLines       7043 non-null object\n",
            "InternetService     7043 non-null object\n",
            "OnlineSecurity      7043 non-null object\n",
            "OnlineBackup        7043 non-null object\n",
            "DeviceProtection    7043 non-null object\n",
            "TechSupport         7043 non-null object\n",
            "StreamingTV         7043 non-null object\n",
            "StreamingMovies     7043 non-null object\n",
            "Contract            7043 non-null object\n",
            "PaperlessBilling    7043 non-null object\n",
            "PaymentMethod       7043 non-null object\n",
            "MonthlyCharges      7043 non-null float64\n",
            "TotalCharges        7043 non-null float64\n",
            "Churn               7043 non-null object\n",
            "dtypes: float64(2), int64(2), object(16)\n",
            "memory usage: 1.1+ MB\n",
            "None\n",
            "   gender  SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n",
            "0  Female              0     Yes  ...          29.85         29.85    No\n",
            "1    Male              0      No  ...          56.95       1889.50    No\n",
            "2    Male              0      No  ...          53.85        108.15   Yes\n",
            "3    Male              0      No  ...          42.30       1840.75    No\n",
            "4  Female              0      No  ...          70.70        151.65   Yes\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JptPeF-IT29g"
      },
      "source": [
        "## Recognizing Categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "783e1da4-c39e-4d77-8bd5-1a404a21ba4d",
        "id": "ezmEK3h-T29h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "colnums = len(df.columns)\n",
        "for i in df.columns:\n",
        "    try:\n",
        "        if df[i].dtype.name == 'object':\n",
        "            df[i] = df[i].astype('category')\n",
        "        else:\n",
        "            df[i].astype('float32')\n",
        "    except:\n",
        "        continue\n",
        "print(df.head())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   gender  SeniorCitizen Partner  ... MonthlyCharges  TotalCharges Churn\n",
            "0  Female              0     Yes  ...          29.85         29.85    No\n",
            "1    Male              0      No  ...          56.95       1889.50    No\n",
            "2    Male              0      No  ...          53.85        108.15   Yes\n",
            "3    Male              0      No  ...          42.30       1840.75    No\n",
            "4  Female              0      No  ...          70.70        151.65   Yes\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "55283518-7ff6-48e4-f396-0a1726bb2170",
        "id": "oapUxtIiT29l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "vals = df.values.copy()\n",
        "total_nums = len(vals)\n",
        "\n",
        "train, validation = train_test_split(df, test_size=0.5, \n",
        "                                     random_state=42, \n",
        "                                     shuffle=True)\n",
        "\n",
        "validation = validation.reindex(sorted(validation.columns), axis=1)\n",
        "validation.to_csv(path + '_For_Test.csv')\n",
        "print(validation.head())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Churn        Contract Dependents  ... TotalCharges  gender  tenure\n",
            "185    Yes  Month-to-month         No  ...        24.80  Female       1\n",
            "2715    No  Month-to-month         No  ...       996.45    Male      41\n",
            "3825    No        Two year        Yes  ...      1031.70  Female      52\n",
            "1807   Yes  Month-to-month         No  ...        76.35  Female       1\n",
            "132     No        Two year         No  ...      3260.10    Male      67\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e8d4c4b9-70a6-4c2c-afec-965619e7f6a8",
        "id": "HAVFi13QT29o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "df = train\n",
        "categorical = df.select_dtypes(['category']).columns\n",
        "print(categorical)\n",
        "for f in categorical:\n",
        "    dummies = pd.get_dummies(df[f], prefix = f, prefix_sep = '_')\n",
        "    df = pd.concat([df, dummies], axis = 1)\n",
        "    \n",
        "# drop original categorical features\n",
        "df.drop(categorical, axis = 1, inplace = True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines',\n",
            "       'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
            "       'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract',\n",
            "       'PaperlessBilling', 'PaymentMethod', 'Churn'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9KXhkZujT29r",
        "colab": {}
      },
      "source": [
        "train = df.values.copy()\n",
        "train.astype('float32')\n",
        "scaler = MinMaxScaler()\n",
        "d = {}\n",
        "train = scaler.fit_transform(train)\n",
        "x_train, x_test = train_test_split(train, test_size=0.5,\n",
        "                                  random_state=24,\n",
        "                                  shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "81412487-a10a-4db4-ae91-1e7da69bfcf7",
        "id": "fa5UJs9cT29v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "original_dim = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, original_dim])\n",
        "x_test = np.reshape(x_test, [-1, original_dim])\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1760, 47)\n",
            "(1761, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MnKFnBX-6LQR",
        "colab": {}
      },
      "source": [
        "from keras.regularizers import l2\n",
        "from keras.losses import categorical_crossentropy\n",
        "class DropoutVAE:\n",
        "    def __init__(self, input_shape=(original_dim,), \n",
        "                 intermediate_dim=32, latent_dim=3, dropout=0.05, \n",
        "                 summary=False):\n",
        "        \n",
        "        self._build_model(input_shape,\n",
        "                         intermediate_dim, \n",
        "                          latent_dim, summary,\n",
        "                          dropout)\n",
        "    \n",
        "    def _build_model(self, input_shape, intermediate_dim, latent_dim,\n",
        "                    summary=False, dropout=0.05):\n",
        "        inputs = Input(shape=input_shape, name='encoder_input')\n",
        "        x = inputs\n",
        "        x = Dense(intermediate_dim, activation='relu')(x)\n",
        "        x = Dense(intermediate_dim//2, activation='relu')(x)\n",
        "        \n",
        "        z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "        z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "        z = Lambda(self.sampling, output_shape=(latent_dim,), \n",
        "                   name='z')([z_mean, z_log_var])\n",
        "\n",
        "        self.encoder = Model(inputs, [z_mean, z_log_var, z], \n",
        "                        name='encoder')\n",
        "        \n",
        "        latent_inputs = Input(shape=(latent_dim,), \n",
        "                              name='z_sampling')\n",
        "        x = latent_inputs\n",
        "        x = Dense(intermediate_dim//2, activation='relu',\n",
        "                 kernel_regularizer=l2(1e-4),\n",
        "                 bias_regularizer=l2(1e-4))(x)\n",
        "        x = Dropout(dropout)(x)\n",
        "        x = Dense(intermediate_dim, activation='relu',\n",
        "                 kernel_regularizer=l2(1e-4),\n",
        "                 bias_regularizer=l2(1e-4))(x)\n",
        "        x = Dropout(dropout)(x)\n",
        "        outputs = Dense(original_dim, activation='sigmoid',\n",
        "                       kernel_regularizer=l2(1e-4),\n",
        "                       bias_regularizer=l2(1e-4))(x)\n",
        "\n",
        "        self.decoder = Model(latent_inputs, \n",
        "                             outputs, \n",
        "                             name='decoder')\n",
        "        outputs = self.decoder(self.encoder(inputs)[2])\n",
        "        self.vae = Model(inputs, outputs, \n",
        "                         name='vae_mlp')\n",
        "        \n",
        "        reconstruction_loss = binary_crossentropy(inputs, outputs)\n",
        "        reconstruction_loss *= original_dim\n",
        "        kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "        kl_loss = K.sum(kl_loss, axis=-1)\n",
        "        kl_loss *= -0.5\n",
        "        \n",
        "        vae_loss = K.mean(reconstruction_loss + kl_loss)\t\n",
        "        \n",
        "        self.vae.add_loss(vae_loss)\n",
        "        self.vae.compile(optimizer='adam')\n",
        "        if summary: \n",
        "            print(self.vae.summary())\n",
        "        \n",
        "    def sampling(self, args):\n",
        "        z_mean, z_log_var = args\n",
        "        batch = K.shape(z_mean)[0]\n",
        "        dim = K.int_shape(z_mean)[1]\n",
        "        epsilon = K.random_normal(shape=(batch, dim))\n",
        "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "        \n",
        "    def fit(self, x_train, x_test, epochs=100, batch_size=100,\n",
        "           verbose=1):\n",
        "        self.vae.fit(x_train, \n",
        "            shuffle=True,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            verbose=verbose,\n",
        "            validation_data=(x_test, None))\n",
        "    \n",
        "    def encoder_predict(self, x_test, batch_size=100):\n",
        "        return self.encoder.predict(x_test,\n",
        "                                   batch_size=batch_size)\n",
        "    \n",
        "    def generate(self, latent_val, batch_size=100):\n",
        "        return self.decoder.predict(latent_val)\n",
        "    \n",
        "    def predict(self, x_test, batch_size=1, nums=1000):\n",
        "        predict_stochastic = K.function([self.vae.layers[0].input,\n",
        "                                        K.learning_phase()],\n",
        "                                        [self.vae.get_output_at(0)])\n",
        "        Yt_hat = np.array([self.vae.predict(x_test) for _ in range(nums)]) \n",
        "        return Yt_hat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TsARTKz36LQZ"
      },
      "source": [
        "## Train and evaluate Dropout VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pkdmVggK6LQp",
        "outputId": "a9b357e7-249a-44ff-d9b6-013a369ef07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3743
        }
      },
      "source": [
        "latent_dim = original_dim//2\n",
        "if latent_dim < 2:\n",
        "    latent_dim = 2\n",
        "vae = DropoutVAE(intermediate_dim=intermediate_dim,\n",
        "                 dropout=0.2, latent_dim=latent_dim,\n",
        "                 summary=True)\n",
        "vae.fit(x_train, x_test, epochs=100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   (None, 47)                0         \n",
            "_________________________________________________________________\n",
            "encoder (Model)              [(None, 23), (None, 23),  167726    \n",
            "_________________________________________________________________\n",
            "decoder (Model)              (None, 47)                161839    \n",
            "=================================================================\n",
            "Total params: 329,565\n",
            "Trainable params: 329,565\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 1760 samples, validate on 1761 samples\n",
            "Epoch 1/100\n",
            "1760/1760 [==============================] - 1s 518us/step - loss: 29.6260 - val_loss: 28.4184\n",
            "Epoch 2/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 28.0914 - val_loss: 27.1512\n",
            "Epoch 3/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 25.9639 - val_loss: 24.5359\n",
            "Epoch 4/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 24.1007 - val_loss: 23.1869\n",
            "Epoch 5/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 23.3513 - val_loss: 22.5808\n",
            "Epoch 6/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 22.9732 - val_loss: 22.3656\n",
            "Epoch 7/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 22.3873 - val_loss: 21.8843\n",
            "Epoch 8/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 22.0361 - val_loss: 21.4108\n",
            "Epoch 9/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 21.8046 - val_loss: 21.1907\n",
            "Epoch 10/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 21.6709 - val_loss: 20.9658\n",
            "Epoch 11/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 21.1972 - val_loss: 20.6972\n",
            "Epoch 12/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 21.0257 - val_loss: 20.5859\n",
            "Epoch 13/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 21.0197 - val_loss: 20.3789\n",
            "Epoch 14/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 20.6430 - val_loss: 20.2737\n",
            "Epoch 15/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 20.5431 - val_loss: 20.1775\n",
            "Epoch 16/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 20.4032 - val_loss: 19.7801\n",
            "Epoch 17/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 20.2180 - val_loss: 19.6047\n",
            "Epoch 18/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 19.9181 - val_loss: 19.4983\n",
            "Epoch 19/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 19.7308 - val_loss: 19.3885\n",
            "Epoch 20/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 19.6313 - val_loss: 19.2128\n",
            "Epoch 21/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 19.6393 - val_loss: 19.1577\n",
            "Epoch 22/100\n",
            "1760/1760 [==============================] - 0s 115us/step - loss: 19.5421 - val_loss: 19.0109\n",
            "Epoch 23/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 19.5620 - val_loss: 19.0735\n",
            "Epoch 24/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 19.3820 - val_loss: 19.0057\n",
            "Epoch 25/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 19.3426 - val_loss: 18.9062\n",
            "Epoch 26/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 19.1843 - val_loss: 18.9713\n",
            "Epoch 27/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 19.1963 - val_loss: 18.7935\n",
            "Epoch 28/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 19.0548 - val_loss: 18.8525\n",
            "Epoch 29/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 19.1802 - val_loss: 18.7718\n",
            "Epoch 30/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 19.0890 - val_loss: 18.7714\n",
            "Epoch 31/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 19.0919 - val_loss: 18.5964\n",
            "Epoch 32/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 19.0919 - val_loss: 18.6689\n",
            "Epoch 33/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 18.9121 - val_loss: 18.4493\n",
            "Epoch 34/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 18.9162 - val_loss: 18.5662\n",
            "Epoch 35/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 18.7471 - val_loss: 18.5792\n",
            "Epoch 36/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 18.7962 - val_loss: 18.3692\n",
            "Epoch 37/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 18.7766 - val_loss: 18.2622\n",
            "Epoch 38/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 18.6539 - val_loss: 18.3643\n",
            "Epoch 39/100\n",
            "1760/1760 [==============================] - 0s 109us/step - loss: 18.5971 - val_loss: 18.2203\n",
            "Epoch 40/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 18.7111 - val_loss: 18.3275\n",
            "Epoch 41/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 18.5638 - val_loss: 18.1623\n",
            "Epoch 42/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 18.6032 - val_loss: 18.2701\n",
            "Epoch 43/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 18.4468 - val_loss: 18.2685\n",
            "Epoch 44/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 18.3272 - val_loss: 18.1477\n",
            "Epoch 45/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 18.3672 - val_loss: 18.0041\n",
            "Epoch 46/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 18.1915 - val_loss: 17.9214\n",
            "Epoch 47/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 18.2860 - val_loss: 17.9087\n",
            "Epoch 48/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 18.2641 - val_loss: 17.9812\n",
            "Epoch 49/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 18.1659 - val_loss: 17.9421\n",
            "Epoch 50/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 18.1910 - val_loss: 17.9761\n",
            "Epoch 51/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 17.9764 - val_loss: 17.7908\n",
            "Epoch 52/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 18.1180 - val_loss: 17.8412\n",
            "Epoch 53/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 18.0435 - val_loss: 17.8275\n",
            "Epoch 54/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 18.1091 - val_loss: 17.6542\n",
            "Epoch 55/100\n",
            "1760/1760 [==============================] - 0s 109us/step - loss: 17.8684 - val_loss: 17.7840\n",
            "Epoch 56/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.8740 - val_loss: 17.7325\n",
            "Epoch 57/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 17.8639 - val_loss: 17.6449\n",
            "Epoch 58/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 17.7760 - val_loss: 17.6287\n",
            "Epoch 59/100\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 17.8792 - val_loss: 17.5278\n",
            "Epoch 60/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 17.9422 - val_loss: 17.5828\n",
            "Epoch 61/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 17.7174 - val_loss: 17.6296\n",
            "Epoch 62/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 17.7759 - val_loss: 17.5795\n",
            "Epoch 63/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 17.7089 - val_loss: 17.4682\n",
            "Epoch 64/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.6207 - val_loss: 17.3458\n",
            "Epoch 65/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.5990 - val_loss: 17.3754\n",
            "Epoch 66/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 17.5563 - val_loss: 17.5077\n",
            "Epoch 67/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 17.4931 - val_loss: 17.3608\n",
            "Epoch 68/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 17.5268 - val_loss: 17.4030\n",
            "Epoch 69/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.5375 - val_loss: 17.3688\n",
            "Epoch 70/100\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 17.5017 - val_loss: 17.3104\n",
            "Epoch 71/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.5072 - val_loss: 17.3144\n",
            "Epoch 72/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 17.3083 - val_loss: 17.2511\n",
            "Epoch 73/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.5023 - val_loss: 17.2011\n",
            "Epoch 74/100\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 17.3093 - val_loss: 17.2877\n",
            "Epoch 75/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.3848 - val_loss: 17.2846\n",
            "Epoch 76/100\n",
            "1760/1760 [==============================] - 0s 113us/step - loss: 17.2776 - val_loss: 17.2253\n",
            "Epoch 77/100\n",
            "1760/1760 [==============================] - 0s 106us/step - loss: 17.3591 - val_loss: 17.0933\n",
            "Epoch 78/100\n",
            "1760/1760 [==============================] - 0s 110us/step - loss: 17.2123 - val_loss: 17.1689\n",
            "Epoch 79/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 17.1982 - val_loss: 17.2042\n",
            "Epoch 80/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.3392 - val_loss: 17.3458\n",
            "Epoch 81/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.3491 - val_loss: 17.4802\n",
            "Epoch 82/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.2775 - val_loss: 17.1275\n",
            "Epoch 83/100\n",
            "1760/1760 [==============================] - 0s 109us/step - loss: 17.1915 - val_loss: 17.1860\n",
            "Epoch 84/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.1631 - val_loss: 17.0449\n",
            "Epoch 85/100\n",
            "1760/1760 [==============================] - 0s 101us/step - loss: 17.1101 - val_loss: 16.9614\n",
            "Epoch 86/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.2312 - val_loss: 17.0633\n",
            "Epoch 87/100\n",
            "1760/1760 [==============================] - 0s 100us/step - loss: 17.2719 - val_loss: 16.9693\n",
            "Epoch 88/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.1541 - val_loss: 16.9212\n",
            "Epoch 89/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 17.1056 - val_loss: 16.9824\n",
            "Epoch 90/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.0716 - val_loss: 16.9917\n",
            "Epoch 91/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 16.9630 - val_loss: 17.0423\n",
            "Epoch 92/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.1320 - val_loss: 17.0335\n",
            "Epoch 93/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 16.8735 - val_loss: 16.9283\n",
            "Epoch 94/100\n",
            "1760/1760 [==============================] - 0s 108us/step - loss: 16.9344 - val_loss: 17.1548\n",
            "Epoch 95/100\n",
            "1760/1760 [==============================] - 0s 102us/step - loss: 17.1393 - val_loss: 17.0789\n",
            "Epoch 96/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 16.8156 - val_loss: 16.9324\n",
            "Epoch 97/100\n",
            "1760/1760 [==============================] - 0s 105us/step - loss: 17.0689 - val_loss: 16.9354\n",
            "Epoch 98/100\n",
            "1760/1760 [==============================] - 0s 104us/step - loss: 17.0101 - val_loss: 16.9727\n",
            "Epoch 99/100\n",
            "1760/1760 [==============================] - 0s 103us/step - loss: 17.0345 - val_loss: 17.0149\n",
            "Epoch 100/100\n",
            "1760/1760 [==============================] - 0s 107us/step - loss: 16.8584 - val_loss: 16.9529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2HndA3MG6LQs",
        "outputId": "ea345844-a516-4af2-f301-f3c5185bb8d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.random.seed(1)\n",
        "x_test = np.reshape(x_test, (-1, original_dim))\n",
        "print(x_test.shape)\n",
        "print(x_test[0].reshape(-1, original_dim).shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1761, 47)\n",
            "(1, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sgO9JKSqWsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_nums = 2\n",
        "results = []\n",
        "for i in range(x_test.shape[0]):\n",
        "    x_test_encoded = vae.predict(x_test[i].reshape(-1, original_dim), \n",
        "                                 nums=total_nums)\n",
        "    x_test_encoded = x_test_encoded.reshape(total_nums, original_dim)\n",
        "    results.append(x_test_encoded)\n",
        "results = np.asarray(results)\n",
        "results = results.reshape(total_nums*results.shape[0], original_dim)\n",
        "results = scaler.inverse_transform(results)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POfJxgHamlmx",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YIlGSzekAYlO",
        "colab": {}
      },
      "source": [
        "d = {}\n",
        "names = list(df)\n",
        "for i, name in enumerate(names):\n",
        "    d[name] = results[:, i]\n",
        "df = pd.DataFrame(data=d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "01e37411-6de4-40af-dbe3-f15908012640",
        "id": "shurAQCSAYlV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "names = list(df)\n",
        "c_dict = {}\n",
        "for n in names:\n",
        "    if '_' in n:\n",
        "        index = n.index('_')\n",
        "        c_dict[n[:index]] = [c for c in names if n[:index+1] in c]\n",
        "values = []\n",
        "for key, items in c_dict.items():\n",
        "    dummies = df[items]\n",
        "    d_names = list(dummies)\n",
        "    c_dict = {}\n",
        "    for n in d_names:\n",
        "        c_dict[n] = n[n.index('_')+1:]\n",
        "    dummies.rename(columns=c_dict, \n",
        "                   inplace=True)\n",
        "    df[key] = dummies.idxmax(axis=1)\n",
        "    df.drop(items, axis=1, inplace=True)\n",
        "print(df.head())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  return super(DataFrame, self).rename(**kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   SeniorCitizen     tenure  ...     PaymentMethod  Churn\n",
            "0       0.002313   3.440300  ...      Mailed check     No\n",
            "1       0.009535   5.950753  ...      Mailed check     No\n",
            "2       0.495956  28.785448  ...  Electronic check     No\n",
            "3       0.367715  36.271164  ...  Electronic check     No\n",
            "4       0.015900  16.980619  ...      Mailed check     No\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8dLIoyVW_Kn",
        "colab": {}
      },
      "source": [
        "df = df.reindex(sorted(df.columns), axis=1)\n",
        "df.to_csv(path + '_dropout.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL6N8v2sYTNm",
        "colab_type": "text"
      },
      "source": [
        "# Transform categorical -> number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgVhmliYYzwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "validation.to_csv(path + '_For_Test.csv')\n",
        "df = pd.read_csv(path + '_For_Test.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df_mc = pd.read_csv(path + '_dropout.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df_vae = pd.read_csv(path + '_vae.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_mc.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_vae.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "names = list(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSbyWbb0ZjAJ",
        "colab_type": "code",
        "outputId": "34f1ae6b-1ab4-4385-9abe-52c49509ac1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "colnums = len(df.columns)\n",
        "for i in df.columns:\n",
        "    try:\n",
        "        if df[i].dtype.name == 'object':\n",
        "            df[i] = df[i].astype('category')\n",
        "    except:\n",
        "        continue\n",
        "cat_columns = df.select_dtypes(['category']).columns\n",
        "print(cat_columns)\n",
        "for col in cat_columns:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col].values)\n",
        "    df_mc[col] = le.transform(df_mc[col].values)\n",
        "    df_vae[col] = le.transform(df_vae[col].values)\n",
        "    "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Churn', 'Contract', 'Dependents', 'DeviceProtection',\n",
            "       'InternetService', 'MultipleLines', 'OnlineBackup', 'OnlineSecurity',\n",
            "       'PaperlessBilling', 'Partner', 'PaymentMethod', 'PhoneService',\n",
            "       'StreamingMovies', 'StreamingTV', 'TechSupport', 'gender'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-scTKTHZ9Wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.reindex(sorted(df.columns), axis=1)\n",
        "df_mc = df_mc.reindex(sorted(df_mc.columns), axis=1)\n",
        "df_vae = df_vae.reindex(sorted(df_vae.columns), axis=1)\n",
        "df.to_csv(path + '_For_Test_encoded.csv')\n",
        "df_mc.to_csv(path + '_dropout_encoded.csv')\n",
        "df_vae.to_csv(path + '_vae_encoded.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLy-z65OUnRj",
        "colab_type": "text"
      },
      "source": [
        "# Predicting with generated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W-tX8ysUuOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(path + '_For_Test_encoded.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df_mc = pd.read_csv(path + '_dropout_encoded.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df_vae = pd.read_csv(path + '_vae_encoded.csv',\n",
        "                 na_filter=True, \n",
        "                 verbose=False, \n",
        "                 skip_blank_lines=True, \n",
        "                 na_values=na_values,\n",
        "                 keep_default_na=False)\n",
        "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_mc.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "df_vae.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F40hUKFVC3E",
        "colab_type": "code",
        "outputId": "1b33d731-1f59-4f3f-caee-42ceb6eca375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "print(df.head())\n",
        "print(df_mc.head())\n",
        "print(df_vae.head())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Churn  Contract  Dependents  ...  TotalCharges  gender  tenure\n",
            "0      1         0           0  ...         24.80       0       1\n",
            "1      0         0           0  ...        996.45       1      41\n",
            "2      0         2           1  ...       1031.70       0      52\n",
            "3      1         0           0  ...         76.35       0       1\n",
            "4      0         2           0  ...       3260.10       1      67\n",
            "\n",
            "[5 rows x 20 columns]\n",
            "   Churn  Contract  Dependents  ...  TotalCharges  gender     tenure\n",
            "0      0         0           0  ...      69.48820       0   3.440300\n",
            "1      0         0           0  ...      74.98905       0   5.950753\n",
            "2      0         0           0  ...    2630.44950       0  28.785448\n",
            "3      0         0           0  ...    3430.79860       0  36.271164\n",
            "4      0         1           0  ...     272.17416       0  16.980620\n",
            "\n",
            "[5 rows x 20 columns]\n",
            "   Churn  Contract  Dependents  ...  TotalCharges  gender     tenure\n",
            "0      0         0           0  ...    1728.00870       1  23.335747\n",
            "1      1         0           0  ...     171.23148       0   6.956230\n",
            "2      1         0           0  ...     399.54498       0   7.282513\n",
            "3      1         1           0  ...    1888.29900       1  29.835083\n",
            "4      0         1           0  ...    1227.26280       0  27.078154\n",
            "\n",
            "[5 rows x 20 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tyhyfWHXbn4",
        "colab_type": "code",
        "outputId": "1c0cf47a-622f-4a35-f829-63a90fa6e7c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y = df['Churn'].values\n",
        "df.drop(['Churn'], axis=1, inplace=True)\n",
        "X = df.values\n",
        "print(y.shape)\n",
        "print(X.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3522,)\n",
            "(3522, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwzr1m5TX5QC",
        "colab_type": "code",
        "outputId": "9790ae72-f62e-416b-fbb9-c684e9487072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_mc = df_mc['Churn'].values\n",
        "df_mc.drop(['Churn'], axis=1, inplace=True)\n",
        "X_mc = df_mc.values\n",
        "print(y_mc.shape)\n",
        "print(X_mc.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3522,)\n",
            "(3522, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbq6H2ZnYXqz",
        "colab_type": "code",
        "outputId": "4eb321ea-b223-41c8-bac3-e46e09aaf7cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_vae = df_vae['Churn'].values\n",
        "df_vae.drop(['Churn'], axis=1, inplace=True)\n",
        "X_vae = df_vae.values\n",
        "print(y_vae.shape)\n",
        "print(X_vae.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3522,)\n",
            "(3522, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8JPft-5a6QL",
        "colab_type": "text"
      },
      "source": [
        "## Cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWMcVL29ggWg",
        "colab_type": "text"
      },
      "source": [
        "### Original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ob3Et0uia9YZ",
        "colab_type": "code",
        "outputId": "a1bc25fb-cb1c-4f18-836d-8b9e00b0ce4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "scores = cross_val_score(clf, X, y, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.77 (+/- 0.03)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hSUz0c0ngkj5"
      },
      "source": [
        "### DropoutVAE generated data with original Outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "db3deabd-ad2c-4866-d224-9a343fd199f0",
        "id": "y4-GzQ_bbPCo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "scores = cross_val_score(clf, X_mc, y, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.73 (+/- 0.00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NL3OtgaGgxQB"
      },
      "source": [
        "### VAE generated data with original outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Crz0AfZ-bSg-",
        "colab_type": "code",
        "outputId": "7fa375c7-9dcf-4e51-cd9b-cb3387bd3887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "scores = cross_val_score(clf, X_vae, y, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.73 (+/- 0.00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mrCqDtssg4nB"
      },
      "source": [
        "### Original data with Dropout VAE outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mH3gS3nacvV7",
        "outputId": "7f35a8b4-6f8c-4ee5-9507-f8d80be3df49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "scores = cross_val_score(clf, X, y_mc, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.77 (+/- 0.00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YlER2gGnhBGJ"
      },
      "source": [
        "### Original data with VAE outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MezW_-9ZcvWA",
        "outputId": "b38b0bda-cdec-4c9e-f7aa-95e7e7762912",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "clf = RandomForestClassifier(n_estimators=100, \n",
        "                             max_depth=2, random_state=42)\n",
        "scores = cross_val_score(clf, X, y_vae, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.74 (+/- 0.00)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}